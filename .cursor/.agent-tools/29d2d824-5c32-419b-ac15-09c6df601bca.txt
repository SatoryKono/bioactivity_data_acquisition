[1m[91mE501 [0m[1mLine too long (128 > 100)[0m
   [1m[94m-->[0m src/library/cli/__init__.py:123:101
    [1m[94m|[0m
[1m[94m121 |[0m def pipeline(
[1m[94m122 |[0m     config: Path = CONFIG_OPTION,
[1m[94m123 |[0m     overrides: list[str] = typer.Option([], "--set", "-s", help="Override configuration values using dotted paths (KEY=VALUE)"),
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m124 |[0m ) -> None:
[1m[94m125 |[0m     """Execute the ETL pipeline using a configuration file."""
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
   [1m[94m-->[0m src/library/cli/__init__.py:207:101
    [1m[94m|[0m
[1m[94m205 |[0m     # Validate that --all and --source are not used together
[1m[94m206 |[0m     if all_sources and sources:
[1m[94m207 |[0m         typer.echo("Error: Cannot use --all and --source together. Use either --all or --source.", err=True)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^[0m
[1m[94m208 |[0m         raise typer.Exit(code=ExitCode.VALIDATION_ERROR)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (106 > 100)[0m
   [1m[94m-->[0m src/library/clients/base.py:150:101
    [1m[94m|[0m
[1m[94m148 |[0m         """Make a request with fallback strategy for handling errors."""
[1m[94m149 |[0m         def _make_request():
[1m[94m150 |[0m             return self._request(method, path, expected_status=expected_status, headers=headers, **kwargs)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^[0m
[1m[94m151 |[0m         
[1m[94m152 |[0m         return self.fallback_manager.execute_with_fallback(_make_request)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/clients/base.py:207:101
    [1m[94m|[0m
[1m[94m205 |[0m                         # –î–ª—è Semantic Scholar –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
[1m[94m206 |[0m                         if 'semanticscholar' in self.base_url.lower():
[1m[94m207 |[0m                             self.logger.info("Using conservative 5-minute delay for Semantic Scholar")
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m208 |[0m                             time.sleep(300)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (116 > 100)[0m
   [1m[94m-->[0m src/library/clients/fallback.py:229:101
    [1m[94m|[0m
[1m[94m228 |[0m                 delay = self.strategy.get_delay(e, attempt)
[1m[94m229 |[0m                 self.logger.info(f"Retry {attempt + 1}/{self.strategy.config.max_retries} after {delay:.2f}s delay")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^[0m
[1m[94m230 |[0m                 time.sleep(delay)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:120:101
    [1m[94m|[0m
[1m[94m118 |[0m             return self._normalise_record(payload)
[1m[94m119 |[0m             
[1m[94m120 |[0m         self.logger.warning("unexpected_payload_format", pmid=pmid, payload_keys=list(payload.keys()))
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m121 |[0m         return None
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:198:101
    [1m[94m|[0m
[1m[94m196 |[0m [1m[94m‚Ä¶[0m     "pubmed_volume": record.get("volume"),
[1m[94m197 |[0m [1m[94m‚Ä¶[0m     "pubmed_issue": record.get("issue"),
[1m[94m198 |[0m [1m[94m‚Ä¶[0m     "pubmed_first_page": record.get("pages", "").split("-")[0] if record.get("pages") else None,
    [1m[94m|[0m                                                                                               [1m[91m^^^^[0m
[1m[94m199 |[0m [1m[94m‚Ä¶[0m     "pubmed_last_page": record.get("pages", "").split("-")[1] if record.get("pages") and "-" in record.get("pages", "") else None,
[1m[94m200 |[0m [1m[94m‚Ä¶[0m     "pubmed_doc_type": pub_type,
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (138 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:199:101
    [1m[94m|[0m
[1m[94m197 |[0m [1m[94m‚Ä¶[0m
[1m[94m198 |[0m [1m[94m‚Ä¶[0m"").split("-")[0] if record.get("pages") else None,
[1m[94m199 |[0m [1m[94m‚Ä¶[0m").split("-")[1] if record.get("pages") and "-" in record.get("pages", "") else None,
    [1m[94m|[0m                                                 [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m200 |[0m [1m[94m‚Ä¶[0m
[1m[94m201 |[0m [1m[94m‚Ä¶[0mrs,
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (113 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:324:101
    [1m[94m|[0m
[1m[94m322 |[0m                 # –ò—â–µ–º abstract –≤ XML - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
[1m[94m323 |[0m                 # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤—Å–µ AbstractText —Ç–µ–≥–∏
[1m[94m324 |[0m                 abstract_matches = re.findall(r'<AbstractText[^>]*>(.*?)</AbstractText>', xml_content, re.DOTALL)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^[0m
[1m[94m325 |[0m                 if abstract_matches:
[1m[94m326 |[0m                     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ abstract
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:340:101
    [1m[94m|[0m
[1m[94m338 |[0m                 if not record.get("pubmed_abstract"):
[1m[94m339 |[0m                     # –ò—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
[1m[94m340 |[0m                     abstract_alt = re.search(r'<Abstract[^>]*>(.*?)</Abstract>', xml_content, re.DOTALL)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m341 |[0m                     if abstract_alt:
[1m[94m342 |[0m                         clean_abstract = re.sub(r'<[^>]+>', '', abstract_alt.group(1)).strip()
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (165 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:347:101
    [1m[94m|[0m
[1m[94m346 |[0m [1m[94m‚Ä¶[0m
[1m[94m347 |[0m [1m[94m‚Ä¶[0m]*>.*?<DescriptorName[^>]*>([^<]+)</DescriptorName>.*?</MeshHeadingList>', xml_content, re.DOTALL)
    [1m[94m|[0m                                   [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m348 |[0m [1m[94m‚Ä¶[0m
[1m[94m349 |[0m [1m[94m‚Ä¶[0mesh_descriptors)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:352:101
    [1m[94m|[0m
[1m[94m351 |[0m                 # –ò–∑–≤–ª–µ–∫–∞–µ–º MeSH qualifiers
[1m[94m352 |[0m                 mesh_qualifiers = re.findall(r'<QualifierName[^>]*>([^<]+)</QualifierName>', xml_content)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m353 |[0m                 if mesh_qualifiers:
[1m[94m354 |[0m                     record["pubmed_mesh_qualifiers"] = "; ".join(mesh_qualifiers)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (158 > 100)[0m
   [1m[94m-->[0m src/library/clients/pubmed.py:357:101
    [1m[94m|[0m
[1m[94m356 |[0m [1m[94m‚Ä¶[0m
[1m[94m357 |[0m [1m[94m‚Ä¶[0m>.*?<NameOfSubstance[^>]*>([^<]+)</NameOfSubstance>.*?</ChemicalList>', xml_content, re.DOTALL)
    [1m[94m|[0m                                       [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m358 |[0m [1m[94m‚Ä¶[0m
[1m[94m359 |[0m [1m[94m‚Ä¶[0mchemical_list)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
   [1m[94m-->[0m src/library/config.py:295:101
    [1m[94m|[0m
[1m[94m294 |[0m     enabled: bool = Field(default=True)
[1m[94m295 |[0m     enhanced: bool = Field(default=False, description="Enable enhanced QC reporting with detailed metrics")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (125 > 100)[0m
   [1m[94m-->[0m src/library/config.py:302:101
    [1m[94m|[0m
[1m[94m301 |[0m     enabled: bool = Field(default=True)
[1m[94m302 |[0m     enhanced: bool = Field(default=False, description="Enable enhanced correlation analysis with multiple correlation types")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
  [1m[94m-->[0m src/library/documents/config.py:71:101
   [1m[94m|[0m
[1m[94m69 |[0m     correlation: SourceToggle = Field(default_factory=lambda: SourceToggle(enabled=False))
[1m[94m70 |[0m     journal_normalization: SourceToggle = Field(default_factory=lambda: SourceToggle(enabled=True))
[1m[94m71 |[0m     citation_formatting: CitationFormattingSettings = Field(default_factory=CitationFormattingSettings)
   [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:134:101
    [1m[94m|[0m
[1m[94m132 |[0m         "chembl_issue": None,
[1m[94m133 |[0m         # Crossref columns  
[1m[94m134 |[0m         "crossref_doi": None, "crossref_title": None, "crossref_doc_type": None, "crossref_subject": None, 
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m135 |[0m         "crossref_error": None,
[1m[94m136 |[0m         # OpenAlex columns
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:188:101
    [1m[94m|[0m
[1m[94m186 |[0m                         if value is not None:
[1m[94m187 |[0m                             row_data[key] = value
[1m[94m188 |[0m                 elif pd.notna(row.get("document_pubmed_id")) and str(row["document_pubmed_id"]).strip():
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m189 |[0m                     data = client.fetch_by_pmid(str(row["document_pubmed_id"]).strip())
[1m[94m190 |[0m                     data.pop("source", None)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:202:101
    [1m[94m|[0m
[1m[94m200 |[0m                         if value is not None:
[1m[94m201 |[0m                             row_data[key] = value
[1m[94m202 |[0m                 elif pd.notna(row.get("document_pubmed_id")) and str(row["document_pubmed_id"]).strip():
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m203 |[0m                     data = client.fetch_by_pmid(str(row["document_pubmed_id"]).strip())
[1m[94m204 |[0m                     data.pop("source", None)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:210:101
    [1m[94m|[0m
[1m[94m209 |[0m             elif source == "pubmed":
[1m[94m210 |[0m                 if pd.notna(row.get("document_pubmed_id")) and str(row["document_pubmed_id"]).strip():
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m211 |[0m                     data = client.fetch_by_pmid(str(row["document_pubmed_id"]).strip())
[1m[94m212 |[0m                     data.pop("source", None)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:218:101
    [1m[94m|[0m
[1m[94m217 |[0m             elif source == "semantic_scholar":
[1m[94m218 |[0m                 if pd.notna(row.get("document_pubmed_id")) and str(row["document_pubmed_id"]).strip():
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m219 |[0m                     data = client.fetch_by_pmid(str(row["document_pubmed_id"]).strip())
[1m[94m220 |[0m                     data.pop("source", None)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:296:101
    [1m[94m|[0m
[1m[94m294 |[0m     # –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞ –Ω–æ–≤—ã–µ
[1m[94m295 |[0m     if "classification" in normalised.columns:
[1m[94m296 |[0m         normalised["document_classification"] = pd.to_numeric(normalised["classification"], errors='coerce')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^[0m
[1m[94m297 |[0m     
[1m[94m298 |[0m     if "document_contains_external_links" in normalised.columns:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (123 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:299:101
    [1m[94m|[0m
[1m[94m298 |[0m     if "document_contains_external_links" in normalised.columns:
[1m[94m299 |[0m         normalised["referenses_on_previous_experiments"] = normalised["document_contains_external_links"].astype('boolean')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m300 |[0m     
[1m[94m301 |[0m     if "is_experimental_doc" in normalised.columns:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (106 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:302:101
    [1m[94m|[0m
[1m[94m301 |[0m     if "is_experimental_doc" in normalised.columns:
[1m[94m302 |[0m         normalised["original_experimental_document"] = normalised["is_experimental_doc"].astype('boolean')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^[0m
[1m[94m303 |[0m     
[1m[94m304 |[0m     # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª—è, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (117 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:306:101
    [1m[94m|[0m
[1m[94m304 |[0m     # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª—è, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
[1m[94m305 |[0m     if "document_classification" in normalised.columns:
[1m[94m306 |[0m         normalised["document_classification"] = pd.to_numeric(normalised["document_classification"], errors='coerce')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^[0m
[1m[94m307 |[0m     
[1m[94m308 |[0m     if "referenses_on_previous_experiments" in normalised.columns:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (125 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:309:101
    [1m[94m|[0m
[1m[94m308 |[0m     if "referenses_on_previous_experiments" in normalised.columns:
[1m[94m309 |[0m         normalised["referenses_on_previous_experiments"] = normalised["referenses_on_previous_experiments"].astype('boolean')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m310 |[0m     
[1m[94m311 |[0m     if "original_experimental_document" in normalised.columns:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (117 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:312:101
    [1m[94m|[0m
[1m[94m311 |[0m     if "original_experimental_document" in normalised.columns:
[1m[94m312 |[0m         normalised["original_experimental_document"] = normalised["original_experimental_document"].astype('boolean')
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^[0m
[1m[94m313 |[0m     
[1m[94m314 |[0m     normalised = normalised.sort_values("document_chembl_id").reset_index(drop=True)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:324:101
    [1m[94m|[0m
[1m[94m322 |[0m     all_columns = {
[1m[94m323 |[0m         # Original ChEMBL fields
[1m[94m324 |[0m         "document_chembl_id", "title", "doi", "document_pubmed_id", "chembl_doc_type", "journal", "year",
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m325 |[0m         # Legacy ChEMBL fields
[1m[94m326 |[0m         "abstract", "pubmed_authors", "document_classification", "referenses_on_previous_experiments",
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/documents/pipeline.py:326:101
    [1m[94m|[0m
[1m[94m324 |[0m         "document_chembl_id", "title", "doi", "document_pubmed_id", "chembl_doc_type", "journal", "year",
[1m[94m325 |[0m         # Legacy ChEMBL fields
[1m[94m326 |[0m         "abstract", "pubmed_authors", "document_classification", "referenses_on_previous_experiments",
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m327 |[0m         "first_page", "original_experimental_document", "issue", "last_page", "month", "volume",
[1m[94m328 |[0m         # Enriched fields from external sources
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_correlation.py:14:101
   [1m[94m|[0m
[1m[94m13 |[0m # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –¥–µ–ª–µ–Ω–∏–∏ –Ω–∞ –Ω–æ–ª—å –≤ NumPy
[1m[94m14 |[0m warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in divide')
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:208:101
    [1m[94m|[0m
[1m[94m206 |[0m                     if n_groups > 1:
[1m[94m207 |[0m                         # –í—ã—á–∏—Å–ª—è–µ–º eta-squared
[1m[94m208 |[0m                         ss_between = grouped.apply(lambda x: (x.mean() - df[num_col].mean())**2 * len(x)).sum()
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m209 |[0m                         ss_total = ((df[num_col] - df[num_col].mean())**2).sum()
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:361:101
    [1m[94m|[0m
[1m[94m359 |[0m             except Exception as e:
[1m[94m360 |[0m                 if self.logger:
[1m[94m361 |[0m                     self.logger.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–≤–æ–¥–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π", error=str(e))
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m362 |[0m
[1m[94m363 |[0m         return summary
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:365:101
    [1m[94m|[0m
[1m[94m363 |[0m         return summary
[1m[94m364 |[0m
[1m[94m365 |[0m     def generate_correlation_reports(self, correlation_analysis: Dict[str, Any]) -> Dict[str, pd.DataFrame]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^[0m
[1m[94m366 |[0m         """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º."""
[1m[94m367 |[0m         reports = {}
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (106 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:397:101
    [1m[94m|[0m
[1m[94m395 |[0m         return reports
[1m[94m396 |[0m
[1m[94m397 |[0m     def generate_correlation_insights(self, correlation_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^[0m
[1m[94m398 |[0m         """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π."""
[1m[94m399 |[0m         insights = []
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (135 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:412:101
    [1m[94m|[0m
[1m[94m410 |[0m [1m[94m‚Ä¶[0m         'type': 'strong_correlation',
[1m[94m411 |[0m [1m[94m‚Ä¶[0m         'severity': 'high',
[1m[94m412 |[0m [1m[94m‚Ä¶[0m         'message': f"–°–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É {corr_matrix.columns[i]} –∏ {corr_matrix.columns[j]}: {corr_val:.3f}",
    [1m[94m|[0m                                                                                   [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m413 |[0m [1m[94m‚Ä¶[0m         'recommendation': "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ—Å—Ç–∞–≤–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞"
[1m[94m414 |[0m [1m[94m‚Ä¶[0m     })
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (132 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:413:101
    [1m[94m|[0m
[1m[94m411 |[0m [1m[94m‚Ä¶[0m             'severity': 'high',
[1m[94m412 |[0m [1m[94m‚Ä¶[0m             'message': f"–°–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É {corr_matrix.columns[i]} –∏ {corr_matrix.columns[j]}: {corr_val:.3f}",
[1m[94m413 |[0m [1m[94m‚Ä¶[0m             'recommendation': "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ—Å—Ç–∞–≤–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞"
    [1m[94m|[0m                                                                                       [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m414 |[0m [1m[94m‚Ä¶[0m         })
[1m[94m415 |[0m [1m[94m‚Ä¶[0m     elif abs(corr_val) > 0.7:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (137 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:419:101
    [1m[94m|[0m
[1m[94m417 |[0m [1m[94m‚Ä¶[0m         'type': 'moderate_correlation',
[1m[94m418 |[0m [1m[94m‚Ä¶[0m         'severity': 'medium',
[1m[94m419 |[0m [1m[94m‚Ä¶[0m         'message': f"–£–º–µ—Ä–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É {corr_matrix.columns[i]} –∏ {corr_matrix.columns[j]}: {corr_val:.3f}",
    [1m[94m|[0m                                                                                   [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m420 |[0m [1m[94m‚Ä¶[0m         'recommendation': "–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π"
[1m[94m421 |[0m [1m[94m‚Ä¶[0m     })
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:420:101
    [1m[94m|[0m
[1m[94m418 |[0m [1m[94m‚Ä¶[0m         'severity': 'medium',
[1m[94m419 |[0m [1m[94m‚Ä¶[0m         'message': f"–£–º–µ—Ä–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É {corr_matrix.columns[i]} –∏ {corr_matrix.columns[j]}: {corr_val:.3f}",
[1m[94m420 |[0m [1m[94m‚Ä¶[0m         'recommendation': "–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π"
    [1m[94m|[0m                                                                                   [1m[91m^^[0m
[1m[94m421 |[0m [1m[94m‚Ä¶[0m     })
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (172 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:434:101
    [1m[94m|[0m
[1m[94m432 |[0m [1m[94m‚Ä¶[0m
[1m[94m433 |[0m [1m[94m‚Ä¶[0m
[1m[94m434 |[0m [1m[94m‚Ä¶[0m–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ {cramers_matrix.columns[i]} –∏ {cramers_matrix.columns[j]}: {cramers_val:.3f}",
    [1m[94m|[0m                                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m435 |[0m [1m[94m‚Ä¶[0m–∫—É—é —Å–≤—è–∑—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏"
[1m[94m436 |[0m [1m[94m‚Ä¶[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:435:101
    [1m[94m|[0m
[1m[94m433 |[0m [1m[94m‚Ä¶[0m         'severity': 'medium',
[1m[94m434 |[0m [1m[94m‚Ä¶[0m         'message': f"–°–∏–ª—å–Ω–∞—è –∞—Å—Å–æ—Ü–∏–∞—Ü–∏—è –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ {cramers_matrix.columns[i]} –∏ {cramers_matrix.columns[j]}[1m[94m‚Ä¶[0m
[1m[94m435 |[0m [1m[94m‚Ä¶[0m         'recommendation': "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å–≤—è–∑—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏"
    [1m[94m|[0m                                                                                   [1m[91m^^^^[0m
[1m[94m436 |[0m [1m[94m‚Ä¶[0m     })
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (114 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:441:101
    [1m[94m|[0m
[1m[94m441 |[0m def build_enhanced_correlation_analysis(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> Dict[str, Any]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^[0m
[1m[94m442 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π."""
[1m[94m443 |[0m     analyzer = EnhancedCorrelationAnalyzer(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (122 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:447:101
    [1m[94m|[0m
[1m[94m447 |[0m def build_enhanced_correlation_reports(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> Dict[str, pd.DataFrame]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m448 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º."""
[1m[94m449 |[0m     analyzer = EnhancedCorrelationAnalyzer(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_correlation.py:454:101
    [1m[94m|[0m
[1m[94m454 |[0m def build_correlation_insights(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> List[Dict[str, Any]]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m455 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º."""
[1m[94m456 |[0m     analyzer = EnhancedCorrelationAnalyzer(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (121 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_qc.py:22:101
   [1m[94m|[0m
[1m[94m20 |[0m             'doi': re.compile(r'10\.\d{4,9}/[-._;()/:A-Z0-9]+', re.IGNORECASE),
[1m[94m21 |[0m             'issn': re.compile(r'\b\d{4}-\d{3}[\dxX]\b'),
[1m[94m22 |[0m             'isbn': re.compile(r'\b(?:ISBN[- ]?(?:13|10)?:? )?(?:97[89][- ]?)?\d{1,5}[- ]?\d{1,7}[- ]?\d{1,6}[- ]?\d\b'),
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m23 |[0m             'url': re.compile(r'https?://[^\s<>"{}|\\^`\[\]]+', re.IGNORECASE),
[1m[94m24 |[0m             'email': re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_qc.py:30:101
   [1m[94m|[0m
[1m[94m28 |[0m         """–ê–Ω–∞–ª–∏–∑ DataFrame –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞."""
[1m[94m29 |[0m         if self.logger:
[1m[94m30 |[0m             self.logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö", rows=len(df), columns=len(df.columns))
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m31 |[0m
[1m[94m32 |[0m         quality_report = {
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_qc.py:62:101
   [1m[94m|[0m
[1m[94m60 |[0m             analysis = {
[1m[94m61 |[0m                 'non_null': int(series.notna().sum()),
[1m[94m62 |[0m                 'non_empty': int(series.notna().sum() - (series.astype(str).str.strip() == '').sum()),
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m63 |[0m                 'empty_pct': float((series.isna().sum() + (series.astype(str).str.strip() == '').sum()) / len(series) * 100),
[1m[94m64 |[0m                 'unique_cnt': int(series.nunique()),
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (125 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_qc.py:63:101
   [1m[94m|[0m
[1m[94m61 |[0m                 'non_null': int(series.notna().sum()),
[1m[94m62 |[0m                 'non_empty': int(series.notna().sum() - (series.astype(str).str.strip() == '').sum()),
[1m[94m63 |[0m                 'empty_pct': float((series.isna().sum() + (series.astype(str).str.strip() == '').sum()) / len(series) * 100),
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m64 |[0m                 'unique_cnt': int(series.nunique()),
[1m[94m65 |[0m                 'unique_pct_of_non_empty': float(series.nunique() / series.notna().sum() * 100) if series.notna().sum() > 0 else 0.0,
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (133 > 100)[0m
  [1m[94m-->[0m src/library/etl/enhanced_qc.py:65:101
   [1m[94m|[0m
[1m[94m63 |[0m                 'empty_pct': float((series.isna().sum() + (series.astype(str).str.strip() == '').sum()) / len(series) * 100),
[1m[94m64 |[0m                 'unique_cnt': int(series.nunique()),
[1m[94m65 |[0m                 'unique_pct_of_non_empty': float(series.nunique() / series.notna().sum() * 100) if series.notna().sum() > 0 else 0.0,
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m66 |[0m                 'dtype': str(series.dtype),
[1m[94m67 |[0m             }
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (117 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_qc.py:127:101
    [1m[94m|[0m
[1m[94m125 |[0m         bool_pattern = re.compile(r'^(true|false|yes|no|1|0|y|n)$', re.IGNORECASE)
[1m[94m126 |[0m         bool_matches = text_series.str.match(bool_pattern, na=False)
[1m[94m127 |[0m         patterns['bool_like_cov'] = float(bool_matches.sum() / total_non_empty * 100) if total_non_empty > 0 else 0.0
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^[0m
[1m[94m128 |[0m         
[1m[94m129 |[0m         return patterns
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_qc.py:206:101
    [1m[94m|[0m
[1m[94m204 |[0m             'missing_data_matrix': df.isnull().sum().to_dict(),
[1m[94m205 |[0m             'duplicate_rows': int(df.duplicated().sum()),
[1m[94m206 |[0m             'memory_per_row': float(df.memory_usage(deep=True).sum() / len(df)) if len(df) > 0 else 0.0,
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m207 |[0m         }
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_qc.py:321:101
    [1m[94m|[0m
[1m[94m321 |[0m def build_enhanced_qc_report(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> dict[str, Any]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m322 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö."""
[1m[94m323 |[0m     profiler = EnhancedTableQualityProfiler(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_qc.py:327:101
    [1m[94m|[0m
[1m[94m327 |[0m def build_enhanced_qc_summary(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> pd.DataFrame:
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m328 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö."""
[1m[94m329 |[0m     profiler = EnhancedTableQualityProfiler(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (114 > 100)[0m
   [1m[94m-->[0m src/library/etl/enhanced_qc.py:334:101
    [1m[94m|[0m
[1m[94m334 |[0m def build_enhanced_qc_detailed(df: pd.DataFrame, logger: Optional[BoundLogger] = None) -> dict[str, pd.DataFrame]:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^[0m
[1m[94m335 |[0m     """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö."""
[1m[94m336 |[0m     profiler = EnhancedTableQualityProfiler(logger=logger)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
  [1m[94m-->[0m src/library/etl/load.py:48:101
   [1m[94m|[0m
[1m[94m47 |[0m     # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
[1m[94m48 |[0m     sort_by = [col for col in (determinism.sort.by or ordered.columns.tolist()) if col in df.columns]
   [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m49 |[0m     
[1m[94m50 |[0m     # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º DataFrame –∫–∞–∫ –µ—Å—Ç—å
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:413:101
    [1m[94m|[0m
[1m[94m411 |[0m         qc_path.parent.mkdir(parents=True, exist_ok=True)
[1m[94m412 |[0m         if file_format == "parquet":
[1m[94m413 |[0m             qc_report.to_parquet(qc_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m414 |[0m         else:
[1m[94m415 |[0m             qc_report.to_csv(qc_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (124 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:425:101
    [1m[94m|[0m
[1m[94m423 |[0m         corr_path.parent.mkdir(parents=True, exist_ok=True)
[1m[94m424 |[0m         if file_format == "parquet":
[1m[94m425 |[0m             correlation.to_parquet(corr_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m426 |[0m         else:
[1m[94m427 |[0m             correlation.to_csv(corr_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (135 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:438:101
    [1m[94m|[0m
[1m[94m436 |[0m [1m[94m‚Ä¶[0mf, logger=logger)
[1m[94m437 |[0m [1m[94m‚Ä¶[0m
[1m[94m438 |[0m [1m[94m‚Ä¶[0math.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                  [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m439 |[0m [1m[94m‚Ä¶[0m
[1m[94m440 |[0m [1m[94m‚Ä¶[0m **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (128 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:449:101
    [1m[94m|[0m
[1m[94m447 |[0m             report_path = detailed_qc_path / f"{report_name}.csv"
[1m[94m448 |[0m             if file_format == "parquet":
[1m[94m449 |[0m                 report_df.to_parquet(report_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m450 |[0m             else:
[1m[94m451 |[0m                 report_df.to_csv(report_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (131 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:470:101
    [1m[94m|[0m
[1m[94m468 |[0m                 report_path = enhanced_corr_path / f"{report_name}.csv"
[1m[94m469 |[0m                 if file_format == "parquet":
[1m[94m470 |[0m                     report_df.to_parquet(report_path.with_suffix('.parquet'), index=True, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m471 |[0m                 else:
[1m[94m472 |[0m                     report_df.to_csv(report_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:494:101
    [1m[94m|[0m
[1m[94m492 |[0m                 return obj
[1m[94m493 |[0m             
[1m[94m494 |[0m             json_analysis = json.loads(json.dumps(detailed_corr_analysis, default=convert_numpy, indent=2))
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m495 |[0m             json.dump(json_analysis, f, ensure_ascii=False, indent=2)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (132 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:503:101
    [1m[94m|[0m
[1m[94m501 |[0m             insights_path = detailed_corr_path / "correlation_insights.csv"
[1m[94m502 |[0m             if file_format == "parquet":
[1m[94m503 |[0m                 insights_df.to_parquet(insights_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m504 |[0m             else:
[1m[94m505 |[0m                 insights_df.to_csv(insights_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:515:101
    [1m[94m|[0m
[1m[94m513 |[0m             logger.info("auto_qc_corr_complete", 
[1m[94m514 |[0m                        qc_files=[str(qc_path), str(enhanced_qc_path), str(detailed_qc_path)],
[1m[94m515 |[0m                        corr_files=[str(corr_path), str(enhanced_corr_path), str(detailed_corr_path)])
    [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m516 |[0m     
[1m[94m517 |[0m     except Exception as e:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (135 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:584:101
    [1m[94m|[0m
[1m[94m582 |[0m [1m[94m‚Ä¶[0mf, logger=logger)
[1m[94m583 |[0m [1m[94m‚Ä¶[0m
[1m[94m584 |[0m [1m[94m‚Ä¶[0math.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                  [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m585 |[0m [1m[94m‚Ä¶[0m
[1m[94m586 |[0m [1m[94m‚Ä¶[0m **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (128 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:595:101
    [1m[94m|[0m
[1m[94m593 |[0m             report_path = detailed_qc_path / f"{report_name}.csv"
[1m[94m594 |[0m             if file_format == "parquet":
[1m[94m595 |[0m                 report_df.to_parquet(report_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m596 |[0m             else:
[1m[94m597 |[0m                 report_df.to_csv(report_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (131 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:623:101
    [1m[94m|[0m
[1m[94m621 |[0m                 report_path = enhanced_corr_path / f"{report_name}.csv"
[1m[94m622 |[0m                 if file_format == "parquet":
[1m[94m623 |[0m                     report_df.to_parquet(report_path.with_suffix('.parquet'), index=True, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m624 |[0m                 else:
[1m[94m625 |[0m                     report_df.to_csv(report_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:647:101
    [1m[94m|[0m
[1m[94m645 |[0m                 return obj
[1m[94m646 |[0m             
[1m[94m647 |[0m             json_analysis = json.loads(json.dumps(detailed_corr_analysis, default=convert_numpy, indent=2))
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m648 |[0m             json.dump(json_analysis, f, ensure_ascii=False, indent=2)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (132 > 100)[0m
   [1m[94m-->[0m src/library/etl/load.py:656:101
    [1m[94m|[0m
[1m[94m654 |[0m             insights_path = detailed_corr_path / "correlation_insights.csv"
[1m[94m655 |[0m             if file_format == "parquet":
[1m[94m656 |[0m                 insights_df.to_parquet(insights_path.with_suffix('.parquet'), index=False, compression=parquet_settings.compression)
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m657 |[0m             else:
[1m[94m658 |[0m                 insights_df.to_csv(insights_path, **_csv_options(csv_settings))
    [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/library/etl/qc.py:19:1
   [1m[94m|[0m
[1m[94m17 |[0m   )
[1m[94m18 |[0m
[1m[94m19 |[0m [1m[91m/[0m from .enhanced_correlation import (
[1m[94m20 |[0m [1m[91m|[0m     build_correlation_insights,
[1m[94m21 |[0m [1m[91m|[0m     build_enhanced_correlation_analysis,
[1m[94m22 |[0m [1m[91m|[0m     build_enhanced_correlation_reports,
[1m[94m23 |[0m [1m[91m|[0m )
   [1m[94m|[0m [1m[91m|_^[0m
[1m[94m24 |[0m   from .enhanced_qc import build_enhanced_qc_detailed, build_enhanced_qc_summary
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/library/etl/qc.py:24:1
   [1m[94m|[0m
[1m[94m22 |[0m     build_enhanced_correlation_reports,
[1m[94m23 |[0m )
[1m[94m24 |[0m from .enhanced_qc import build_enhanced_qc_detailed, build_enhanced_qc_summary
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
  [1m[94m-->[0m src/library/etl/transform.py:88:101
   [1m[94m|[0m
[1m[94m86 |[0m     # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–ª–æ–Ω–∫–∏
[1m[94m87 |[0m     columns_to_drop = ["activity_units", "standard_units", "standard_value"]
[1m[94m88 |[0m     normalized = normalized.drop(columns=[col for col in columns_to_drop if col in normalized.columns], errors="ignore")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m89 |[0m
[1m[94m90 |[0m     # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏, —É–∫–∞–∑–∞–Ω–Ω—ã–µ –≤ column_order
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/library/schemas/document_input_schema.py:14:1
   [1m[94m|[0m
[1m[94m12 |[0m else:  # pragma: no cover - import side effect
[1m[94m13 |[0m     import pandera as pa
[1m[94m14 |[0m from pandera.typing import Series
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_input_schema.py:36:101
   [1m[94m|[0m
[1m[94m34 |[0m         nullable=True, description="Document authors from PubMed"
[1m[94m35 |[0m     )
[1m[94m36 |[0m     document_classification: Series[float] = pa.Field(nullable=True, description="Document classification")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m37 |[0m     referenses_on_previous_experiments: Series[bool] = pa.Field(nullable=True, description="Contains external links")
[1m[94m38 |[0m     first_page: Series[int] = pa.Field(nullable=True, description="First page number")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (117 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_input_schema.py:37:101
   [1m[94m|[0m
[1m[94m35 |[0m     )
[1m[94m36 |[0m     document_classification: Series[float] = pa.Field(nullable=True, description="Document classification")
[1m[94m37 |[0m     referenses_on_previous_experiments: Series[bool] = pa.Field(nullable=True, description="Contains external links")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^[0m
[1m[94m38 |[0m     first_page: Series[int] = pa.Field(nullable=True, description="First page number")
[1m[94m39 |[0m     original_experimental_document: Series[bool] = pa.Field(nullable=True, description="Is experimental document")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (114 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_input_schema.py:39:101
   [1m[94m|[0m
[1m[94m37 |[0m     referenses_on_previous_experiments: Series[bool] = pa.Field(nullable=True, description="Contains external links")
[1m[94m38 |[0m     first_page: Series[int] = pa.Field(nullable=True, description="First page number")
[1m[94m39 |[0m     original_experimental_document: Series[bool] = pa.Field(nullable=True, description="Is experimental document")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^[0m
[1m[94m40 |[0m     issue: Series[int] = pa.Field(nullable=True, description="Journal issue number")
[1m[94m41 |[0m     last_page: Series[float] = pa.Field(nullable=True, description="Last page number")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_output_schema.py:32:101
   [1m[94m|[0m
[1m[94m30 |[0m         nullable=True, description="Document authors from PubMed"
[1m[94m31 |[0m     )
[1m[94m32 |[0m     document_classification: Series[float] = pa.Field(nullable=True, description="Document classification")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m33 |[0m     referenses_on_previous_experiments: Series[bool] = pa.Field(
[1m[94m34 |[0m         nullable=True, description="Contains external links"
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_output_schema.py:68:101
   [1m[94m|[0m
[1m[94m66 |[0m     openalex_volume: Series[str] = pa.Field(nullable=True, description="Volume from OpenAlex")
[1m[94m67 |[0m     openalex_issue: Series[str] = pa.Field(nullable=True, description="Issue from OpenAlex")
[1m[94m68 |[0m     openalex_first_page: Series[str] = pa.Field(nullable=True, description="First page from OpenAlex")
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m69 |[0m     openalex_last_page: Series[str] = pa.Field(nullable=True, description="Last page from OpenAlex")
[1m[94m70 |[0m     openalex_error: Series[str] = pa.Field(nullable=True, description="Error from OpenAlex")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m src/library/schemas/document_output_schema.py:88:101
   [1m[94m|[0m
[1m[94m86 |[0m     crossref_volume: Series[str] = pa.Field(nullable=True, description="Volume from Crossref")
[1m[94m87 |[0m     crossref_issue: Series[str] = pa.Field(nullable=True, description="Issue from Crossref")
[1m[94m88 |[0m     crossref_first_page: Series[str] = pa.Field(nullable=True, description="First page from Crossref")
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m89 |[0m     crossref_last_page: Series[str] = pa.Field(nullable=True, description="Last page from Crossref")
[1m[94m90 |[0m     crossref_error: Series[str] = pa.Field(nullable=True, description="Error from Crossref")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
   [1m[94m-->[0m src/library/schemas/document_output_schema.py:182:101
    [1m[94m|[0m
[1m[94m181 |[0m     # Citation field
[1m[94m182 |[0m     document_citation: Series[str] = pa.Field(nullable=True, description="Formatted citation string")
    [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m183 |[0m     
[1m[94m184 |[0m     # Validation fields
    [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/library/schemas/input_schema.py:14:1
   [1m[94m|[0m
[1m[94m12 |[0m else:  # pragma: no cover - import side effect
[1m[94m13 |[0m     import pandera as pa
[1m[94m14 |[0m from pandera.typing import Series
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (122 > 100)[0m
  [1m[94m-->[0m src/library/schemas/input_schema.py:21:101
   [1m[94m|[0m
[1m[94m20 |[0m     # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∏–∑ ChEMBL API
[1m[94m21 |[0m     # molecule_chembl_id: Series[str] = pa.Field(nullable=True)  # compound_id —É–¥–∞–ª–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m22 |[0m     target_pref_name: Series[str] = pa.Field(nullable=True)
[1m[94m23 |[0m     standard_value: Series[float] = pa.Field(nullable=True)  # activity_value –≤ ChEMBL
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
  [1m[94m-->[0m src/library/schemas/output_schema.py:20:101
   [1m[94m|[0m
[1m[94m18 |[0m     """Schema for normalized bioactivity data ready for export."""
[1m[94m19 |[0m
[1m[94m20 |[0m     # compound_id: Series[str] = pa.Field(nullable=True)  # –£–¥–∞–ª–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m21 |[0m     target: Series[str] = pa.Field(nullable=True)
[1m[94m22 |[0m     activity_value: Series[float] = pa.Field(nullable=True)  # –†–∞–∑—Ä–µ—à–∞–µ–º NULL –∑–Ω–∞—á–µ–Ω–∏—è
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (184 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:38:101
   [1m[94m|[0m
[1m[94m36 |[0m [1m[94m‚Ä¶[0m
[1m[94m37 |[0m [1m[94m‚Ä¶[0mmantic_scholar_')],
[1m[94m38 |[0m [1m[94m‚Ä¶[0mid', 'journal', 'year', 'volume', 'issue', 'first_page', 'last_page', 'month', 'abstract', 'pubmed_authors']
   [1m[94m|[0m                          [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m39 |[0m [1m[94m‚Ä¶[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:54:101
   [1m[94m|[0m
[1m[94m52 |[0m         if total_cells > 0:
[1m[94m53 |[0m             fill_percentage = (filled_count / total_cells) * 100
[1m[94m54 |[0m             print(f"{source:<20} {filled_count:4d}/{total_cells:4d} —è—á–µ–µ–∫ ({fill_percentage:5.1f}%)")
   [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m55 |[0m     
[1m[94m56 |[0m     # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (117 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:71:101
   [1m[94m|[0m
[1m[94m69 |[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
[1m[94m70 |[0m     fully_filled_rows = df.notna().all(axis=1).sum()
[1m[94m71 |[0m     print(f"–ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {fully_filled_rows}/{total_rows} ({fully_filled_rows/total_rows*100:.1f}%)")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^[0m
[1m[94m72 |[0m     
[1m[94m73 |[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (125 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:78:101
   [1m[94m|[0m
[1m[94m76 |[0m     avg_fill_per_row = df.notna().sum(axis=1).mean()
[1m[94m77 |[0m     
[1m[94m78 |[0m     print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {min_fill_per_row}/{total_columns} ({min_fill_per_row/total_columns*100:.1f}%)")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m79 |[0m     print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {max_fill_per_row}/{total_columns} ({max_fill_per_row/total_columns*100:.1f}%)")
[1m[94m80 |[0m     print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {avg_fill_per_row:.1f}/{total_columns} ({avg_fill_per_row/total_columns*100:.1f}%)")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (126 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:79:101
   [1m[94m|[0m
[1m[94m78 |[0m     print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {min_fill_per_row}/{total_columns} ({min_fill_per_row/total_columns*100:.1f}%)")
[1m[94m79 |[0m     print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {max_fill_per_row}/{total_columns} ({max_fill_per_row/total_columns*100:.1f}%)")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m80 |[0m     print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {avg_fill_per_row:.1f}/{total_columns} ({avg_fill_per_row/total_columns*100:.1f}%)")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (125 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:80:101
   [1m[94m|[0m
[1m[94m78 |[0m     print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {min_fill_per_row}/{total_columns} ({min_fill_per_row/total_columns*100:.1f}%)")
[1m[94m79 |[0m     print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {max_fill_per_row}/{total_columns} ({max_fill_per_row/total_columns*100:.1f}%)")
[1m[94m80 |[0m     print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ: {avg_fill_per_row:.1f}/{total_columns} ({avg_fill_per_row/total_columns*100:.1f}%)")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m81 |[0m     
[1m[94m82 |[0m     # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
  [1m[94m-->[0m src/library/tools/analyze_fixed_results.py:97:101
   [1m[94m|[0m
[1m[94m96 |[0m         if filled_columns:
[1m[94m97 |[0m             print(f"{source}: {', '.join(filled_columns[:5])}{'...' if len(filled_columns) > 5 else ''}")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m98 |[0m
[1m[94m99 |[0m def main():
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/tools/api_health_check.py:191:101
    [1m[94m|[0m
[1m[94m189 |[0m         recommendations.append("–ù–µ–∫–æ—Ç–æ—Ä—ã–µ API –æ—Ç–≤–µ—á–∞—é—Ç –º–µ–¥–ª–µ–Ω–Ω–æ:")
[1m[94m190 |[0m         for api in slow_apis:
[1m[94m191 |[0m             recommendations.append(f"- {api['api']}: {api['response_time']}—Å (—Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ)")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m192 |[0m     
[1m[94m193 |[0m     if rate_limited_apis:
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (109 > 100)[0m
  [1m[94m-->[0m src/library/tools/check_field_fill.py:28:101
   [1m[94m|[0m
[1m[94m26 |[0m         'Crossref': ['crossref_title', 'crossref_doc_type', 'crossref_subject', 'doi_key'],
[1m[94m27 |[0m         'OpenAlex': ['openalex_title', 'openalex_doc_type', 'openalex_year', 'openalex_doi'],
[1m[94m28 |[0m         'PubMed': ['pubmed_pmid', 'pubmed_doi', 'pubmed_article_title', 'pubmed_abstract', 'pubmed_journal'],
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^[0m
[1m[94m29 |[0m         'Semantic Scholar': ['semantic_scholar_pmid', 'semantic_scholar_doi', 'semantic_scholar_journal', 'semantic_scholar_doc_type']
[1m[94m30 |[0m     }
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (134 > 100)[0m
  [1m[94m-->[0m src/library/tools/check_field_fill.py:29:101
   [1m[94m|[0m
[1m[94m27 |[0m         'OpenAlex': ['openalex_title', 'openalex_doc_type', 'openalex_year', 'openalex_doi'],
[1m[94m28 |[0m         'PubMed': ['pubmed_pmid', 'pubmed_doi', 'pubmed_article_title', 'pubmed_abstract', 'pubmed_journal'],
[1m[94m29 |[0m         'Semantic Scholar': ['semantic_scholar_pmid', 'semantic_scholar_doi', 'semantic_scholar_journal', 'semantic_scholar_doc_type']
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m30 |[0m     }
   [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/check_semantic_scholar_status.py:60:13
   [1m[94m|[0m
[1m[94m58 |[0m                 }
[1m[94m59 |[0m                 result['message'] = "[OK] API —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ"
[1m[94m60 |[0m             except:
   [1m[94m|[0m             [1m[91m^^^^^^[0m
[1m[94m61 |[0m                 result['data_received'] = {'json_parse_error': True}
[1m[94m62 |[0m                 result['message'] = "[WARN] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –Ω–æ –Ω–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ"
   [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/check_semantic_scholar_status.py:69:13
   [1m[94m|[0m
[1m[94m67 |[0m                 error_data = response.json()
[1m[94m68 |[0m                 result['error_details'] = error_data
[1m[94m69 |[0m             except:
   [1m[94m|[0m             [1m[91m^^^^^^[0m
[1m[94m70 |[0m                 result['error_details'] = {'raw_response': response.text}
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_semantic_scholar_status.py:181:101
    [1m[94m|[0m
[1m[94m179 |[0m     parser = argparse.ArgumentParser(description="–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ Semantic Scholar API")
[1m[94m180 |[0m     parser.add_argument("--test-limits", action="store_true", help="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–∏–º–∏—Ç—ã API")
[1m[94m181 |[0m     parser.add_argument("--requests", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m182 |[0m     parser.add_argument("--pmid", type=str, default="7154002", help="PMID –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_specific_limits.py:105:101
    [1m[94m|[0m
[1m[94m103 |[0m [1m[94m‚Ä¶[0m     table.add_row("–°—Ç–∞—Ç—É—Å", status)
[1m[94m104 |[0m [1m[94m‚Ä¶[0m     table.add_row("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞", f"{response_time:.3f}—Å")
[1m[94m105 |[0m [1m[94m‚Ä¶[0m     table.add_row("–ë–µ–∑ –∫–ª—é—á–∞ (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(pubmed_info["rate_limits"]["without_key"]["requests_per_second"]))
    [1m[94m|[0m                                                                                                   [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m106 |[0m [1m[94m‚Ä¶[0m     table.add_row("–° –∫–ª—é—á–æ–º (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(pubmed_info["rate_limits"]["with_key"]["requests_per_second"]))
[1m[94m107 |[0m [1m[94m‚Ä¶[0m     table.add_row("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è", pubmed_info["authentication"])
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (116 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_specific_limits.py:106:101
    [1m[94m|[0m
[1m[94m104 |[0m [1m[94m‚Ä¶[0m     table.add_row("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞", f"{response_time:.3f}—Å")
[1m[94m105 |[0m [1m[94m‚Ä¶[0m     table.add_row("–ë–µ–∑ –∫–ª—é—á–∞ (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(pubmed_info["rate_limits"]["without_key"]["requests_per_second"]))
[1m[94m106 |[0m [1m[94m‚Ä¶[0m     table.add_row("–° –∫–ª—é—á–æ–º (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(pubmed_info["rate_limits"]["with_key"]["requests_per_second"]))
    [1m[94m|[0m                                                                                                   [1m[91m^^^^^^^^^^^^^^^^[0m
[1m[94m107 |[0m [1m[94m‚Ä¶[0m     table.add_row("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è", pubmed_info["authentication"])
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (110 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_specific_limits.py:160:101
    [1m[94m|[0m
[1m[94m158 |[0m         table.add_row("–°—Ç–∞—Ç—É—Å", status)
[1m[94m159 |[0m         table.add_row("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞", f"{response_time:.3f}—Å")
[1m[94m160 |[0m         table.add_row("Free (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(crossref_info["rate_limits"]["free"]["requests_per_second"]))
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^[0m
[1m[94m161 |[0m         table.add_row("Plus (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(crossref_info["rate_limits"]["plus"]["requests_per_second"]))
[1m[94m162 |[0m         table.add_row("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è", crossref_info["authentication"])
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (110 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_specific_limits.py:161:101
    [1m[94m|[0m
[1m[94m159 |[0m         table.add_row("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞", f"{response_time:.3f}—Å")
[1m[94m160 |[0m         table.add_row("Free (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(crossref_info["rate_limits"]["free"]["requests_per_second"]))
[1m[94m161 |[0m         table.add_row("Plus (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)", str(crossref_info["rate_limits"]["plus"]["requests_per_second"]))
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^[0m
[1m[94m162 |[0m         table.add_row("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è", crossref_info["authentication"])
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
   [1m[94m-->[0m src/library/tools/check_specific_limits.py:207:101
    [1m[94m|[0m
[1m[94m205 |[0m         table.add_row("–°—Ç–∞—Ç—É—Å", status)
[1m[94m206 |[0m         table.add_row("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞", f"{response_time:.3f}—Å")
[1m[94m207 |[0m         table.add_row("–ó–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É", str(openalex_info["rate_limits"]["requests_per_second"]))
    [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m208 |[0m         table.add_row("–ó–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É", str(openalex_info["rate_limits"]["requests_per_minute"]))
[1m[94m209 |[0m         table.add_row("–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è", openalex_info["authentication"])
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m src/library/tools/citation_formatter.py:166:101
    [1m[94m|[0m
[1m[94m166 |[0m def add_citation_column(df: pd.DataFrame, column_mapping: dict[str, str] | None = None) -> pd.DataFrame:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m167 |[0m     """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫—É —Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –∫ DataFrame.
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
  [1m[94m-->[0m src/library/tools/data_validator.py:41:101
   [1m[94m|[0m
[1m[94m40 |[0m     # –ü–æ–ª—è DOI –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
[1m[94m41 |[0m     doi_fields = ['chembl_doi', 'crossref_doi', 'openalex_doi', 'pubmed_doi', 'semantic_scholar_doi']
   [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m42 |[0m     
[1m[94m43 |[0m     # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m src/library/tools/data_validator.py:111:101
    [1m[94m|[0m
[1m[94m110 |[0m     # –ü–æ–ª—è journal –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
[1m[94m111 |[0m     journal_fields = ['chembl_journal', 'crossref_journal', 'pubmed_journal', 'semantic_scholar_journal']
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m112 |[0m     
[1m[94m113 |[0m     invalid_journal = []
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (124 > 100)[0m
   [1m[94m-->[0m src/library/tools/data_validator.py:139:101
    [1m[94m|[0m
[1m[94m137 |[0m         else:
[1m[94m138 |[0m             # –ù–µ—Å–∫–æ–ª—å–∫–æ journal - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
[1m[94m139 |[0m             chembl_journal = _normalize_value(row['chembl_journal']) if not _is_empty_value(row['chembl_journal']) else None
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m140 |[0m             
[1m[94m141 |[0m             matches = 0
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (121 > 100)[0m
   [1m[94m-->[0m src/library/tools/data_validator.py:303:101
    [1m[94m|[0m
[1m[94m301 |[0m         else:
[1m[94m302 |[0m             # –ù–µ—Å–∫–æ–ª—å–∫–æ volume - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
[1m[94m303 |[0m             chembl_volume = _normalize_value(row['chembl_volume']) if not _is_empty_value(row['chembl_volume']) else None
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m304 |[0m             
[1m[94m305 |[0m             matches = 0
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (118 > 100)[0m
   [1m[94m-->[0m src/library/tools/data_validator.py:376:101
    [1m[94m|[0m
[1m[94m374 |[0m         else:
[1m[94m375 |[0m             # –ù–µ—Å–∫–æ–ª—å–∫–æ issue - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
[1m[94m376 |[0m             chembl_issue = _normalize_value(row['chembl_issue']) if not _is_empty_value(row['chembl_issue']) else None
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^[0m
[1m[94m377 |[0m             
[1m[94m378 |[0m             matches = 0
    [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/debug_csv_save_load.py:68:5
   [1m[94m|[0m
[1m[94m66 |[0m         os.remove(test_file)
[1m[94m67 |[0m         print(f"   –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} —É–¥–∞–ª–µ–Ω")
[1m[94m68 |[0m     except:
   [1m[94m|[0m     [1m[91m^^^^^^[0m
[1m[94m69 |[0m         pass
   [1m[94m|[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not real_data['invalid_doi']:` for false checks[0m
  [1m[94m-->[0m src/library/tools/debug_csv_save_load.py:88:28
   [1m[94m|[0m
[1m[94m87 |[0m             # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ False –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m88 |[0m             false_count = (real_data['invalid_doi'] == False).sum()
   [1m[94m|[0m                            [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m89 |[0m             print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ False –∑–Ω–∞—á–µ–Ω–∏–π: {false_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not real_data['invalid_doi']`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `real_data['invalid_doi']:` for truth checks[0m
  [1m[94m-->[0m src/library/tools/debug_csv_save_load.py:92:27
   [1m[94m|[0m
[1m[94m91 |[0m             # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ True –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m92 |[0m             true_count = (real_data['invalid_doi'] == True).sum()
   [1m[94m|[0m                           [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m93 |[0m             print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ True –∑–Ω–∞—á–µ–Ω–∏–π: {true_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `real_data['invalid_doi']`[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_doi_validation_issue.py:80:101
   [1m[94m|[0m
[1m[94m79 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ DOI –Ω–µ –ø—É—Å—Ç—ã–µ
[1m[94m80 |[0m         doi_fields = ['chembl_doi', 'crossref_doi', 'openalex_doi', 'pubmed_doi', 'semantic_scholar_doi']
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m81 |[0m         non_empty_dois = []
[1m[94m82 |[0m         for field in doi_fields:
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_doi_validation_issue.py:95:101
   [1m[94m|[0m
[1m[94m93 |[0m         else:
[1m[94m94 |[0m             # –ù–µ—Å–∫–æ–ª—å–∫–æ DOI - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
[1m[94m95 |[0m             chembl_doi = _normalize_value(row['chembl_doi']) if not _is_empty_value(row['chembl_doi']) else None
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^[0m
[1m[94m96 |[0m             print(f"     ChEMBL DOI (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π): {repr(chembl_doi)}")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (135 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_enriched_data.py:46:101
   [1m[94m|[0m
[1m[94m45 |[0m     print("1. –¢–µ—Å—Ç–æ–≤—ã–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
[1m[94m46 |[0m     print(test_data[['document_chembl_id', 'doi', 'chembl_doi', 'crossref_doi', 'openalex_doi', 'pubmed_doi', 'semantic_scholar_doi']])
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m47 |[0m     print()
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (114 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_missing_data.py:36:101
   [1m[94m|[0m
[1m[94m34 |[0m     if crossref_empty.sum() > 0:
[1m[94m35 |[0m         print("\n–ó–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º Crossref:")
[1m[94m36 |[0m         empty_crossref = df[crossref_empty][['document_chembl_id', 'doi', 'document_pubmed_id', 'crossref_error']]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^[0m
[1m[94m37 |[0m         for _, row in empty_crossref.head(5).iterrows():
[1m[94m38 |[0m             print(f"  {row['document_chembl_id']}: DOI={row['doi']}, PMID={row['document_pubmed_id']}, Error={row['crossref_error']}")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (134 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_missing_data.py:38:101
   [1m[94m|[0m
[1m[94m36 |[0m         empty_crossref = df[crossref_empty][['document_chembl_id', 'doi', 'document_pubmed_id', 'crossref_error']]
[1m[94m37 |[0m         for _, row in empty_crossref.head(5).iterrows():
[1m[94m38 |[0m             print(f"  {row['document_chembl_id']}: DOI={row['doi']}, PMID={row['document_pubmed_id']}, Error={row['crossref_error']}")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m39 |[0m     
[1m[94m40 |[0m     # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAlex
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (114 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_missing_data.py:52:101
   [1m[94m|[0m
[1m[94m50 |[0m     if openalex_empty.sum() > 0:
[1m[94m51 |[0m         print("\n–ó–∞–ø–∏—Å–∏ —Å –ø—É—Å—Ç—ã–º OpenAlex:")
[1m[94m52 |[0m         empty_openalex = df[openalex_empty][['document_chembl_id', 'doi', 'document_pubmed_id', 'openalex_error']]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^[0m
[1m[94m53 |[0m         for _, row in empty_openalex.head(5).iterrows():
[1m[94m54 |[0m             print(f"  {row['document_chembl_id']}: DOI={row['doi']}, PMID={row['document_pubmed_id']}, Error={row['openalex_error']}")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (134 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_missing_data.py:54:101
   [1m[94m|[0m
[1m[94m52 |[0m         empty_openalex = df[openalex_empty][['document_chembl_id', 'doi', 'document_pubmed_id', 'openalex_error']]
[1m[94m53 |[0m         for _, row in empty_openalex.head(5).iterrows():
[1m[94m54 |[0m             print(f"  {row['document_chembl_id']}: DOI={row['doi']}, PMID={row['document_pubmed_id']}, Error={row['openalex_error']}")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m55 |[0m     
[1m[94m56 |[0m     # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_execution.py:63:101
   [1m[94m|[0m
[1m[94m62 |[0m                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
[1m[94m63 |[0m                 validation_columns = [col for col in result_df.columns if 'invalid_' in col or 'valid_' in col]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m64 |[0m                 print(f"   –ö–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_columns}")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_execution_real.py:63:101
   [1m[94m|[0m
[1m[94m62 |[0m                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
[1m[94m63 |[0m                 validation_columns = [col for col in result_df.columns if 'invalid_' in col or 'valid_' in col]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m64 |[0m                 print(f"   –ö–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_columns}")
   [1m[94m|[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not result_df['invalid_doi']:` for false checks[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_execution_real.py:80:36
   [1m[94m|[0m
[1m[94m79 |[0m                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ False –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m80 |[0m                     false_count = (result_df['invalid_doi'] == False).sum()
   [1m[94m|[0m                                    [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m81 |[0m                     print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ False –∑–Ω–∞—á–µ–Ω–∏–π: {false_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not result_df['invalid_doi']`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `result_df['invalid_doi']:` for truth checks[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_execution_real.py:84:35
   [1m[94m|[0m
[1m[94m83 |[0m                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ True –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m84 |[0m                     true_count = (result_df['invalid_doi'] == True).sum()
   [1m[94m|[0m                                   [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m85 |[0m                     print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ True –∑–Ω–∞—á–µ–Ω–∏–π: {true_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `result_df['invalid_doi']`[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_validation_issue.py:63:101
   [1m[94m|[0m
[1m[94m62 |[0m                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
[1m[94m63 |[0m                 validation_columns = [col for col in result_df.columns if 'invalid_' in col or 'valid_' in col]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m64 |[0m                 print(f"   –ö–æ–ª–æ–Ω–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_columns}")
   [1m[94m|[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not result_df['invalid_doi']:` for false checks[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_validation_issue.py:80:36
   [1m[94m|[0m
[1m[94m79 |[0m                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ False –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m80 |[0m                     false_count = (result_df['invalid_doi'] == False).sum()
   [1m[94m|[0m                                    [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m81 |[0m                     print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ False –∑–Ω–∞—á–µ–Ω–∏–π: {false_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not result_df['invalid_doi']`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `result_df['invalid_doi']:` for truth checks[0m
  [1m[94m-->[0m src/library/tools/debug_pipeline_validation_issue.py:84:35
   [1m[94m|[0m
[1m[94m83 |[0m                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ True –∑–Ω–∞—á–µ–Ω–∏—è
[1m[94m84 |[0m                     true_count = (result_df['invalid_doi'] == True).sum()
   [1m[94m|[0m                                   [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m85 |[0m                     print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ True –∑–Ω–∞—á–µ–Ω–∏–π: {true_count}")
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `result_df['invalid_doi']`[0m

[1m[91mE501 [0m[1mLine too long (110 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_real_data_validation.py:31:101
   [1m[94m|[0m
[1m[94m30 |[0m     # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ DOI
[1m[94m31 |[0m     doi_cols = [col for col in df.columns if 'doi' in col.lower() and col not in ['invalid_doi', 'valid_doi']]
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^[0m
[1m[94m32 |[0m     print(f"2. –ö–æ–ª–æ–Ω–∫–∏ DOI: {doi_cols}")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_validation_logic.py:48:101
   [1m[94m|[0m
[1m[94m47 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ DOI –Ω–µ –ø—É—Å—Ç—ã–µ
[1m[94m48 |[0m         doi_fields = ['chembl_doi', 'crossref_doi', 'openalex_doi', 'pubmed_doi', 'semantic_scholar_doi']
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m49 |[0m         non_empty_dois = []
[1m[94m50 |[0m         for field in doi_fields:
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
  [1m[94m-->[0m src/library/tools/debug_validation_logic.py:63:101
   [1m[94m|[0m
[1m[94m61 |[0m         else:
[1m[94m62 |[0m             # –ù–µ—Å–∫–æ–ª—å–∫–æ DOI - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
[1m[94m63 |[0m             chembl_doi = _normalize_value(row['chembl_doi']) if not _is_empty_value(row['chembl_doi']) else None
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^[0m
[1m[94m64 |[0m             print(f"     ChEMBL DOI (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π): {repr(chembl_doi)}")
   [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/get_pubmed_api_key.py:67:13
   [1m[94m|[0m
[1m[94m65 |[0m                 else:
[1m[94m66 |[0m                     print("‚ö†Ô∏è –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è")
[1m[94m67 |[0m             except:
   [1m[94m|[0m             [1m[91m^^^^^^[0m
[1m[94m68 |[0m                 print("‚ö†Ô∏è –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –Ω–æ –Ω–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ")
   [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/monitor_pubmed.py:71:17
   [1m[94m|[0m
[1m[94m69 |[0m                         'pmid_found': test_pmid in str(data),
[1m[94m70 |[0m                     }
[1m[94m71 |[0m                 except:
   [1m[94m|[0m                 [1m[91m^^^^^^[0m
[1m[94m72 |[0m                     result['data_received'] = {'json_parse_error': True}
[1m[94m73 |[0m             else:
   [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
  [1m[94m-->[0m src/library/tools/monitor_pubmed.py:85:21
   [1m[94m|[0m
[1m[94m83 |[0m                             'api_key': error_data.get('api-key'),
[1m[94m84 |[0m                         }
[1m[94m85 |[0m                     except:
   [1m[94m|[0m                     [1m[91m^^^^^^[0m
[1m[94m86 |[0m                         pass
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:126:101
    [1m[94m|[0m
[1m[94m124 |[0m                     'rate_limit_current': count,
[1m[94m125 |[0m                     'usage_percent': round(usage_percent, 1),
[1m[94m126 |[0m                     'status': 'critical' if usage_percent > 90 else 'warning' if usage_percent > 70 else 'good'
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m127 |[0m                 })
    [1m[94m|[0m

[1m[91mE722 [0m[1mDo not use bare `except`[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:171:21
    [1m[94m|[0m
[1m[94m169 |[0m                         error_data = response.json()
[1m[94m170 |[0m                         result['rate_limit_info'] = error_data
[1m[94m171 |[0m                     except:
    [1m[94m|[0m                     [1m[91m^^^^^^[0m
[1m[94m172 |[0m                         pass
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:235:100
    [1m[94m|[0m
[1m[94m233 |[0m                             'critical': 'üî¥'
[1m[94m234 |[0m                         }
[1m[94m235 |[0m                         print(f" {status_emoji.get(result['status'], '‚ö™')} {result['usage_percent']}%", end="")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^[0m
[1m[94m236 |[0m                 else:
[1m[94m237 |[0m                     print("‚ùå ERROR")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:323:101
    [1m[94m|[0m
[1m[94m321 |[0m     parser = argparse.ArgumentParser(description="–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ PubMed E-utilities API")
[1m[94m322 |[0m     parser.add_argument("--single", action="store_true", help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–Ω—É –ø—Ä–æ–≤–µ—Ä–∫—É")
[1m[94m323 |[0m     parser.add_argument("--test-limits", action="store_true", help="–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–∏–º–∏—Ç—ã")
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m324 |[0m     parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)")
[1m[94m325 |[0m     parser.add_argument("--duration", type=int, default=10, help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–º–∏–Ω—É—Ç—ã)")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:324:101
    [1m[94m|[0m
[1m[94m322 |[0m     parser.add_argument("--single", action="store_true", help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–Ω—É –ø—Ä–æ–≤–µ—Ä–∫—É")
[1m[94m323 |[0m     parser.add_argument("--test-limits", action="store_true", help="–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–∏–º–∏—Ç—ã")
[1m[94m324 |[0m     parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)")
    [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m325 |[0m     parser.add_argument("--duration", type=int, default=10, help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–º–∏–Ω—É—Ç—ã)")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (106 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_pubmed.py:325:101
    [1m[94m|[0m
[1m[94m323 |[0m     parser.add_argument("--test-limits", action="store_true", help="–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–∏–º–∏—Ç—ã")
[1m[94m324 |[0m     parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)")
[1m[94m325 |[0m     parser.add_argument("--duration", type=int, default=10, help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–º–∏–Ω—É—Ç—ã)")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^[0m
[1m[94m326 |[0m     
[1m[94m327 |[0m     args = parser.parse_args()
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_semantic_scholar.py:113:101
    [1m[94m|[0m
[1m[94m111 |[0m                 'rate_limit_remaining': remaining,
[1m[94m112 |[0m                 'usage_percent': round(usage_percent, 1),
[1m[94m113 |[0m                 'status': 'critical' if usage_percent > 90 else 'warning' if usage_percent > 70 else 'good'
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m114 |[0m             })
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_semantic_scholar.py:151:100
    [1m[94m|[0m
[1m[94m149 |[0m                             'critical': 'üî¥'
[1m[94m150 |[0m                         }
[1m[94m151 |[0m                         print(f" {status_emoji.get(result['status'], '‚ö™')} {result['usage_percent']}%", end="")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^[0m
[1m[94m152 |[0m                 else:
[1m[94m153 |[0m                     print("‚ùå ERROR")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_semantic_scholar.py:237:101
    [1m[94m|[0m
[1m[94m235 |[0m     parser = argparse.ArgumentParser(description="–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Semantic Scholar API")
[1m[94m236 |[0m     parser.add_argument("--single", action="store_true", help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–Ω—É –ø—Ä–æ–≤–µ—Ä–∫—É")
[1m[94m237 |[0m     parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)")
    [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m238 |[0m     parser.add_argument("--duration", type=int, default=10, help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–º–∏–Ω—É—Ç—ã)")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (106 > 100)[0m
   [1m[94m-->[0m src/library/tools/monitor_semantic_scholar.py:238:101
    [1m[94m|[0m
[1m[94m236 |[0m     parser.add_argument("--single", action="store_true", help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–Ω—É –ø—Ä–æ–≤–µ—Ä–∫—É")
[1m[94m237 |[0m     parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)")
[1m[94m238 |[0m     parser.add_argument("--duration", type=int, default=10, help="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–º–∏–Ω—É—Ç—ã)")
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^[0m
[1m[94m239 |[0m     
[1m[94m240 |[0m     args = parser.parse_args()
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
  [1m[94m-->[0m src/library/tools/toggle_semantic_scholar.py:61:101
   [1m[94m|[0m
[1m[94m59 |[0m     print(f"–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {'[OK]' if main_config.exists() else '[MISSING]'}")
[1m[94m60 |[0m     print(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {'[OK]' if backup_config.exists() else '[MISSING]'}")
[1m[94m61 |[0m     print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–µ–∑ Semantic Scholar: {'[OK]' if no_scholar_config.exists() else '[MISSING]'}")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m62 |[0m     
[1m[94m63 |[0m     if main_config.exists():
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (109 > 100)[0m
  [1m[94m-->[0m src/library/tools/toggle_semantic_scholar.py:95:101
   [1m[94m|[0m
[1m[94m93 |[0m     parser.add_argument("--disable", action="store_true", help="–û—Ç–∫–ª—é—á–∏—Ç—å Semantic Scholar API")
[1m[94m94 |[0m     parser.add_argument("--status", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
[1m[94m95 |[0m     parser.add_argument("--backup", action="store_true", help="–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^[0m
[1m[94m96 |[0m     
[1m[94m97 |[0m     args = parser.parse_args()
   [1m[94m|[0m

[1m[91mE741 [0m[1mAmbiguous variable name: `l`[0m
   [1m[94m-->[0m src/library/utils/rate_limit.py:134:38
    [1m[94m|[0m
[1m[94m133 |[0m     def __init__(self, *limiters: RateLimiter | None) -> None:
[1m[94m134 |[0m         self._limiters = tuple(l for l in limiters if l is not None)
    [1m[94m|[0m                                      [1m[91m^[0m
[1m[94m135 |[0m
[1m[94m136 |[0m     def acquire(self) -> None:
    [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:20:1
   [1m[94m|[0m
[1m[94m19 |[0m # Local imports
[1m[94m20 |[0m from library.clients import BaseApiClient as BasePublicationsClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m21 |[0m from library.clients.chembl import ChEMBLClient as ChemblClient  # type: ignore
[1m[94m22 |[0m from library.clients.crossref import CrossrefClient  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:21:1
   [1m[94m|[0m
[1m[94m19 |[0m # Local imports
[1m[94m20 |[0m from library.clients import BaseApiClient as BasePublicationsClient  # type: ignore
[1m[94m21 |[0m from library.clients.chembl import ChEMBLClient as ChemblClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m22 |[0m from library.clients.crossref import CrossrefClient  # type: ignore
[1m[94m23 |[0m from library.clients.openalex import OpenAlexClient  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:22:1
   [1m[94m|[0m
[1m[94m20 |[0m from library.clients import BaseApiClient as BasePublicationsClient  # type: ignore
[1m[94m21 |[0m from library.clients.chembl import ChEMBLClient as ChemblClient  # type: ignore
[1m[94m22 |[0m from library.clients.crossref import CrossrefClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m23 |[0m from library.clients.openalex import OpenAlexClient  # type: ignore
[1m[94m24 |[0m from library.clients.pubmed import PubMedClient  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:23:1
   [1m[94m|[0m
[1m[94m21 |[0m from library.clients.chembl import ChEMBLClient as ChemblClient  # type: ignore
[1m[94m22 |[0m from library.clients.crossref import CrossrefClient  # type: ignore
[1m[94m23 |[0m from library.clients.openalex import OpenAlexClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m24 |[0m from library.clients.pubmed import PubMedClient  # type: ignore
[1m[94m25 |[0m from library.clients.semantic_scholar import SemanticScholarClient  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:24:1
   [1m[94m|[0m
[1m[94m22 |[0m from library.clients.crossref import CrossrefClient  # type: ignore
[1m[94m23 |[0m from library.clients.openalex import OpenAlexClient  # type: ignore
[1m[94m24 |[0m from library.clients.pubmed import PubMedClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m25 |[0m from library.clients.semantic_scholar import SemanticScholarClient  # type: ignore
[1m[94m26 |[0m from library.config import APIClientConfig as ClientConfig  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:25:1
   [1m[94m|[0m
[1m[94m23 |[0m from library.clients.openalex import OpenAlexClient  # type: ignore
[1m[94m24 |[0m from library.clients.pubmed import PubMedClient  # type: ignore
[1m[94m25 |[0m from library.clients.semantic_scholar import SemanticScholarClient  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m26 |[0m from library.config import APIClientConfig as ClientConfig  # type: ignore
[1m[94m27 |[0m from library.logger import configure_logging, get_logger  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:26:1
   [1m[94m|[0m
[1m[94m24 |[0m from library.clients.pubmed import PubMedClient  # type: ignore
[1m[94m25 |[0m from library.clients.semantic_scholar import SemanticScholarClient  # type: ignore
[1m[94m26 |[0m from library.config import APIClientConfig as ClientConfig  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m27 |[0m from library.logger import configure_logging, get_logger  # type: ignore
[1m[94m28 |[0m from library.utils.errors import ConfigError, ExtractionError  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:27:1
   [1m[94m|[0m
[1m[94m25 |[0m from library.clients.semantic_scholar import SemanticScholarClient  # type: ignore
[1m[94m26 |[0m from library.config import APIClientConfig as ClientConfig  # type: ignore
[1m[94m27 |[0m from library.logger import configure_logging, get_logger  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m28 |[0m from library.utils.errors import ConfigError, ExtractionError  # type: ignore
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/fetch_publications.py:28:1
   [1m[94m|[0m
[1m[94m26 |[0m from library.config import APIClientConfig as ClientConfig  # type: ignore
[1m[94m27 |[0m from library.logger import configure_logging, get_logger  # type: ignore
[1m[94m28 |[0m from library.utils.errors import ConfigError, ExtractionError  # type: ignore
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m29 |[0m
[1m[94m30 |[0m try:
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:11:1
   [1m[94m|[0m
[1m[94m 9 |[0m sys.path.insert(0, str(src_dir))
[1m[94m10 |[0m
[1m[94m11 |[0m from library.documents.config import load_document_config
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m12 |[0m from library.documents.pipeline import run_document_etl, read_document_input, write_document_outputs
   [1m[94m|[0m

[1m[91mE402 [0m[1mModule level import not at top of file[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:12:1
   [1m[94m|[0m
[1m[94m11 |[0m from library.documents.config import load_document_config
[1m[94m12 |[0m from library.documents.pipeline import run_document_etl, read_document_input, write_document_outputs
   [1m[94m|[0m [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (115 > 100)[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:29:101
   [1m[94m|[0m
[1m[94m27 |[0m [1m[94m‚Ä¶[0m     config = load_document_config(config_path)
[1m[94m28 |[0m [1m[94m‚Ä¶[0m     print(f"[OK] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_path}")
[1m[94m29 |[0m [1m[94m‚Ä¶[0m     print(f"[OK] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {'–≤–∫–ª—é—á–µ–Ω' if config.postprocess.correlation.enabled else '–æ—Ç–∫–ª—é—á–µ–Ω'}")
   [1m[94m|[0m                                                                                                   [1m[91m^^^^^^^^^^^^^^^[0m
[1m[94m30 |[0m [1m[94m‚Ä¶[0m     print(f"[OK] QC –∞–Ω–∞–ª–∏–∑: {'–≤–∫–ª—é—á–µ–Ω' if config.postprocess.qc.enabled else '–æ—Ç–∫–ª—é—á–µ–Ω'}")
[1m[94m31 |[0m [1m[94m‚Ä¶[0m     print()
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:61:101
   [1m[94m|[0m
[1m[94m59 |[0m [1m[94m‚Ä¶[0m     if result.correlation_analysis:
[1m[94m60 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω")
[1m[94m61 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã: {len(result.correlation_reports) if result.correlation_reports else 0}")
   [1m[94m|[0m                                                                                                   [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m62 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ò–Ω—Å–∞–π—Ç—ã: {len(result.correlation_insights) if result.correlation_insights else 0}")
[1m[94m63 |[0m [1m[94m‚Ä¶[0m     else:
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:62:101
   [1m[94m|[0m
[1m[94m60 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω")
[1m[94m61 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã: {len(result.correlation_reports) if result.correlation_reports else 0}")
[1m[94m62 |[0m [1m[94m‚Ä¶[0m         print(f"[OK] –ò–Ω—Å–∞–π—Ç—ã: {len(result.correlation_insights) if result.correlation_insights else 0}")
   [1m[94m|[0m                                                                                                   [1m[91m^^^^^^^^[0m
[1m[94m63 |[0m [1m[94m‚Ä¶[0m     else:
[1m[94m64 |[0m [1m[94m‚Ä¶[0m         print("[WARN] –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
  [1m[94m-->[0m src/scripts/test_correlation_demo.py:83:101
   [1m[94m|[0m
[1m[94m81 |[0m             print("[STATS] –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π:")
[1m[94m82 |[0m             high_severity = [i for i in result.correlation_insights if i.get('severity') == 'high']
[1m[94m83 |[0m             medium_severity = [i for i in result.correlation_insights if i.get('severity') == 'medium']
   [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m84 |[0m             
[1m[94m85 |[0m             print(f"  - –í—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å: {len(high_severity)} –∏–Ω—Å–∞–π—Ç–æ–≤")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (113 > 100)[0m
  [1m[94m-->[0m tests/cli/test_get_document_data.py:93:101
   [1m[94m|[0m
[1m[94m93 |[0m def test_dry_run_skips_output_writes(monkeypatch: pytest.MonkeyPatch, tmp_path: Path, runner: CliRunner) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^[0m
[1m[94m94 |[0m     input_csv = tmp_path / "input.csv"
[1m[94m95 |[0m     _write_input(input_csv)
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
  [1m[94m-->[0m tests/scripts/test_cli_wrappers.py:22:101
   [1m[94m|[0m
[1m[94m21 |[0m @pytest.mark.parametrize("script_name", SCRIPTS)
[1m[94m22 |[0m def test_legacy_wrapper_delegates_to_bioactivity_cli(script_name: str, monkeypatch: pytest.MonkeyPatch) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^[0m
[1m[94m23 |[0m     """Executing legacy scripts should invoke the canonical CLI entry point."""
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
  [1m[94m-->[0m tests/test_auto_qc_correlation.py:62:101
   [1m[94m|[0m
[1m[94m60 |[0m [1m[94m‚Ä¶[0m     # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
[1m[94m61 |[0m [1m[94m‚Ä¶[0m     enhanced_qc_path = data_dir / f"{data_stem}_quality_report_enhanced.csv"
[1m[94m62 |[0m [1m[94m‚Ä¶[0m     assert enhanced_qc_path.exists(), f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω: {enhanced_qc_path}"
   [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^[0m
[1m[94m63 |[0m [1m[94m‚Ä¶[0m     
[1m[94m64 |[0m [1m[94m‚Ä¶[0m     # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã QC
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
  [1m[94m-->[0m tests/test_auto_qc_correlation.py:66:101
   [1m[94m|[0m
[1m[94m64 |[0m [1m[94m‚Ä¶[0m     # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã QC
[1m[94m65 |[0m [1m[94m‚Ä¶[0m     detailed_qc_path = data_dir / f"{data_stem}_quality_report_detailed"
[1m[94m66 |[0m [1m[94m‚Ä¶[0m     assert detailed_qc_path.exists(), f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞: {detailed_qc_path}"
   [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m67 |[0m [1m[94m‚Ä¶[0m     
[1m[94m68 |[0m [1m[94m‚Ä¶[0m     # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (138 > 100)[0m
  [1m[94m-->[0m tests/test_auto_qc_correlation.py:70:101
   [1m[94m|[0m
[1m[94m68 |[0m [1m[94m‚Ä¶[0m
[1m[94m69 |[0m [1m[94m‚Ä¶[0mtem}_correlation_report_enhanced"
[1m[94m70 |[0m [1m[94m‚Ä¶[0m–µ–∫—Ç–æ—Ä–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞: {enhanced_corr_path}"
   [1m[94m|[0m                                                 [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m71 |[0m [1m[94m‚Ä¶[0m
[1m[94m72 |[0m [1m[94m‚Ä¶[0m
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (136 > 100)[0m
  [1m[94m-->[0m tests/test_auto_qc_correlation.py:74:101
   [1m[94m|[0m
[1m[94m72 |[0m [1m[94m‚Ä¶[0m
[1m[94m73 |[0m [1m[94m‚Ä¶[0mstem}_correlation_report_detailed"
[1m[94m74 |[0m [1m[94m‚Ä¶[0m—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞: {detailed_corr_path}"
   [1m[94m|[0m                                                  [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m75 |[0m [1m[94m‚Ä¶[0m
[1m[94m76 |[0m [1m[94m‚Ä¶[0m–∞
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (108 > 100)[0m
  [1m[94m-->[0m tests/test_auto_qc_correlation.py:95:101
   [1m[94m|[0m
[1m[94m93 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã
[1m[94m94 |[0m [1m[94m‚Ä¶[0m     corr_enhanced_files = list(enhanced_corr_path.glob("*.csv"))
[1m[94m95 |[0m [1m[94m‚Ä¶[0m     assert len(corr_enhanced_files) > 0, "–í —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ñ–∞–π–ª—ã"
   [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^[0m
[1m[94m96 |[0m [1m[94m‚Ä¶[0m     
[1m[94m97 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å—Ç—å JSON —Ñ–∞–π–ª
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:151:101
    [1m[94m|[0m
[1m[94m149 |[0m [1m[94m‚Ä¶[0m     # –î–ª—è –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç—ã –Ω–µ –¥–æ–ª–∂–Ω—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è
[1m[94m150 |[0m [1m[94m‚Ä¶[0m     assert not qc_path.exists(), "QC –æ—Ç—á–µ—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è –¥–ª—è –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
[1m[94m151 |[0m [1m[94m‚Ä¶[0m     assert not corr_path.exists(), "–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è –¥–ª—è –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^[0m
[1m[94m152 |[0m [1m[94m‚Ä¶[0m     
[1m[94m153 |[0m [1m[94m‚Ä¶[0m     print("–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç–æ–≥–æ DataFrame –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:169:101
    [1m[94m|[0m
[1m[94m168 |[0m         # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏–º–µ–Ω–µ–º
[1m[94m169 |[0m         with tempfile.NamedTemporaryFile(mode='w', suffix='_test_data.csv', delete=False) as tmp_file:
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m170 |[0m             data_path = Path(tmp_file.name)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (116 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:192:101
    [1m[94m|[0m
[1m[94m190 |[0m [1m[94m‚Ä¶[0m     expected_detailed_corr_path = data_dir / f"{data_stem}_correlation_report_detailed"
[1m[94m191 |[0m [1m[94m‚Ä¶[0m     
[1m[94m192 |[0m [1m[94m‚Ä¶[0m     assert expected_qc_path.exists(), f"QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_qc_path}"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^^^^^^^[0m
[1m[94m193 |[0m [1m[94m‚Ä¶[0m     assert expected_corr_path.exists(), f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_corr_path}"
[1m[94m194 |[0m [1m[94m‚Ä¶[0m     assert expected_enhanced_qc_path.exists(), f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_qc[1m[94m‚Ä¶[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (132 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:193:101
    [1m[94m|[0m
[1m[94m192 |[0m [1m[94m‚Ä¶[0m     assert expected_qc_path.exists(), f"QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_qc_path}"
[1m[94m193 |[0m [1m[94m‚Ä¶[0m     assert expected_corr_path.exists(), f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_corr_path}"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m194 |[0m [1m[94m‚Ä¶[0m     assert expected_enhanced_qc_path.exists(), f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_qc[1m[94m‚Ä¶[0m
[1m[94m195 |[0m [1m[94m‚Ä¶[0m     assert expected_detailed_qc_path.exists(), f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected[1m[94m‚Ä¶[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (146 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:194:101
    [1m[94m|[0m
[1m[94m192 |[0m [1m[94m‚Ä¶[0m–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_qc_path}"
[1m[94m193 |[0m [1m[94m‚Ä¶[0m—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_corr_path}"
[1m[94m194 |[0m [1m[94m‚Ä¶[0m–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_qc_path}"
    [1m[94m|[0m                                             [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m195 |[0m [1m[94m‚Ä¶[0m–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_qc_path}"
[1m[94m196 |[0m [1m[94m‚Ä¶[0mf"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_corr_path}"
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (158 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:195:101
    [1m[94m|[0m
[1m[94m193 |[0m [1m[94m‚Ä¶[0m–π –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_corr_path}"
[1m[94m194 |[0m [1m[94m‚Ä¶[0m–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_qc_path}"
[1m[94m195 |[0m [1m[94m‚Ä¶[0m–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_qc_path}"
    [1m[94m|[0m                                       [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m196 |[0m [1m[94m‚Ä¶[0m–∫—Ç–æ—Ä–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_corr_path}"
[1m[94m197 |[0m [1m[94m‚Ä¶[0m–∫—Ç–æ—Ä–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_corr_path}"
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (176 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:196:101
    [1m[94m|[0m
[1m[94m194 |[0m [1m[94m‚Ä¶[0m–æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_qc_path}"
[1m[94m195 |[0m [1m[94m‚Ä¶[0m–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_qc_path}"
[1m[94m196 |[0m [1m[94m‚Ä¶[0m—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_corr_path}"
    [1m[94m|[0m                              [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m197 |[0m [1m[94m‚Ä¶[0m—Ç–∞–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_corr_path}"
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (174 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:197:101
    [1m[94m|[0m
[1m[94m195 |[0m [1m[94m‚Ä¶[0m–∞–ª—å–Ω—ã—Ö QC –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_qc_path}"
[1m[94m196 |[0m [1m[94m‚Ä¶[0m–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_enhanced_corr_path}"
[1m[94m197 |[0m [1m[94m‚Ä¶[0m–µ—Ç–∞–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: {expected_detailed_corr_path}"
    [1m[94m|[0m                               [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m198 |[0m [1m[94m‚Ä¶[0m
[1m[94m199 |[0m [1m[94m‚Ä¶[0m)
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (112 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:250:101
    [1m[94m|[0m
[1m[94m249 |[0m [1m[94m‚Ä¶[0m     # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å 4 —Å—Ç—Ä–æ–∫–∏ (–ø–æ –æ–¥–Ω–æ–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏) –ø–ª—é—Å summary
[1m[94m250 |[0m [1m[94m‚Ä¶[0m     assert len(qc_report) >= 4, f"QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 4 —Å—Ç—Ä–æ–∫–∏, –ø–æ–ª—É—á–µ–Ω–æ {len(qc_report)}"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^^^[0m
[1m[94m251 |[0m [1m[94m‚Ä¶[0m     
[1m[94m252 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ QC –æ—Ç—á–µ—Ç–µ
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:262:101
    [1m[94m|[0m
[1m[94m261 |[0m [1m[94m‚Ä¶[0m     # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –±–æ–ª—å—à–µ –º–µ—Ç—Ä–∏–∫
[1m[94m262 |[0m [1m[94m‚Ä¶[0m     assert len(enhanced_qc_report) >= 4, "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 4 —Å—Ç—Ä–æ–∫–∏"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^[0m
[1m[94m263 |[0m [1m[94m‚Ä¶[0m     
[1m[94m264 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (110 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:265:101
    [1m[94m|[0m
[1m[94m264 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
[1m[94m265 |[0m [1m[94m‚Ä¶[0m     enhanced_metrics = ['non_null', 'non_empty', 'empty_pct', 'unique_cnt', 'unique_pct_of_non_empty']
    [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^[0m
[1m[94m266 |[0m [1m[94m‚Ä¶[0m     for metric in enhanced_metrics:
[1m[94m267 |[0m [1m[94m‚Ä¶[0m         assert metric in enhanced_qc_report.columns, f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É '{metric}'"
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (120 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:267:101
    [1m[94m|[0m
[1m[94m265 |[0m [1m[94m‚Ä¶[0m     enhanced_metrics = ['non_null', 'non_empty', 'empty_pct', 'unique_cnt', 'unique_pct_of_non_empty']
[1m[94m266 |[0m [1m[94m‚Ä¶[0m     for metric in enhanced_metrics:
[1m[94m267 |[0m [1m[94m‚Ä¶[0m         assert metric in enhanced_qc_report.columns, f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π QC –æ—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É '{metric}'"
    [1m[94m|[0m                                                                                               [1m[91m^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m268 |[0m [1m[94m‚Ä¶[0m     
[1m[94m269 |[0m [1m[94m‚Ä¶[0m     print("–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –æ—Ç—á–µ—Ç–æ–≤ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (109 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:277:101
    [1m[94m|[0m
[1m[94m276 |[0m             # –£–¥–∞–ª—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
[1m[94m277 |[0m             for suffix in ['_quality_report.csv', '_correlation_report.csv', '_quality_report_enhanced.csv']:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^[0m
[1m[94m278 |[0m                 report_path = data_dir / f"{data_stem}{suffix}"
[1m[94m279 |[0m                 if report_path.exists():
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (119 > 100)[0m
   [1m[94m-->[0m tests/test_auto_qc_correlation.py:282:101
    [1m[94m|[0m
[1m[94m280 |[0m                     os.unlink(report_path)
[1m[94m281 |[0m             
[1m[94m282 |[0m             for suffix in ['_quality_report_detailed', '_correlation_report_enhanced', '_correlation_report_detailed']:
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^[0m
[1m[94m283 |[0m                 report_dir = data_dir / f"{data_stem}{suffix}"
[1m[94m284 |[0m                 if report_dir.exists():
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
   [1m[94m-->[0m tests/test_clients.py:292:101
    [1m[94m|[0m
[1m[94m290 |[0m         responses.GET,
[1m[94m291 |[0m         "https://api.semanticscholar.org/graph/v1/paper/PMID:777",
[1m[94m292 |[0m         match=[responses.matchers.query_param_matcher({"fields": ",".join(client._DEFAULT_FIELDS)})],
    [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m293 |[0m         json={
[1m[94m294 |[0m             "externalIds": {"PubMed": "PMID:777"},
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
  [1m[94m-->[0m tests/test_config.py:61:101
   [1m[94m|[0m
[1m[94m61 |[0m def test_load_applies_defaults_and_secrets(monkeypatch: pytest.MonkeyPatch, config_yaml: Path) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m62 |[0m     """Loading a config merges defaults and resolves secrets."""
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (107 > 100)[0m
  [1m[94m-->[0m tests/test_config.py:70:101
   [1m[94m|[0m
[1m[94m70 |[0m def test_environment_overrides_take_precedence(monkeypatch: pytest.MonkeyPatch, config_yaml: Path) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^[0m
[1m[94m71 |[0m     """Environment variables override YAML values."""
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
  [1m[94m-->[0m tests/test_config.py:79:101
   [1m[94m|[0m
[1m[94m79 |[0m def test_cli_overrides_win_over_environment(monkeypatch: pytest.MonkeyPatch, config_yaml: Path) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m80 |[0m     """CLI overrides have the highest priority."""
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (101 > 100)[0m
  [1m[94m-->[0m tests/test_config_layering.py:54:101
   [1m[94m|[0m
[1m[94m54 |[0m def test_config_loads_and_applies_overrides(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
   [1m[94m|[0m                                                                                                     [1m[91m^[0m
[1m[94m55 |[0m     config_path = write_config(tmp_path)
[1m[94m56 |[0m     monkeypatch.setenv("BIOACTIVITY__HTTP__GLOBAL__TIMEOUT_SEC", "30")
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m tests/test_data_normalization.py:43:101
   [1m[94m|[0m
[1m[94m41 |[0m                 assert pd.isna(actual), f"–ü–æ–∑–∏—Ü–∏—è {i}: –æ–∂–∏–¥–∞–ª—Å—è NA, –ø–æ–ª—É—á–µ–Ω–æ {actual}"
[1m[94m42 |[0m             else:
[1m[94m43 |[0m                 assert actual == expected, f"–ü–æ–∑–∏—Ü–∏—è {i}: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected}', –ø–æ–ª—É—á–µ–Ω–æ '{actual}'"
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m44 |[0m         
[1m[94m45 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ç–æ—Ä—É—é –∫–æ–ª–æ–Ω–∫—É
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
  [1m[94m-->[0m tests/test_data_normalization.py:51:101
   [1m[94m|[0m
[1m[94m49 |[0m                 assert pd.isna(actual), f"–ü–æ–∑–∏—Ü–∏—è {i}: –æ–∂–∏–¥–∞–ª—Å—è NA, –ø–æ–ª—É—á–µ–Ω–æ {actual}"
[1m[94m50 |[0m             else:
[1m[94m51 |[0m                 assert actual == expected, f"–ü–æ–∑–∏—Ü–∏—è {i}: –æ–∂–∏–¥–∞–ª–æ—Å—å '{expected}', –ø–æ–ª—É—á–µ–Ω–æ '{actual}'"
   [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m52 |[0m
[1m[94m53 |[0m     def test_numeric_normalization(self):
   [1m[94m|[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `normalized_df['bool_col'].iloc[0]:` for truth checks[0m
  [1m[94m-->[0m tests/test_data_normalization.py:92:16
   [1m[94m|[0m
[1m[94m91 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Å—Ç–∞–ª–∏—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏
[1m[94m92 |[0m         assert normalized_df['bool_col'].iloc[0] == True
   [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m93 |[0m         assert normalized_df['bool_col'].iloc[1] == False
[1m[94m94 |[0m         assert normalized_df['bool_col'].iloc[3] == True
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `normalized_df['bool_col'].iloc[0]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not normalized_df['bool_col'].iloc[1]:` for false checks[0m
  [1m[94m-->[0m tests/test_data_normalization.py:93:16
   [1m[94m|[0m
[1m[94m91 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Å—Ç–∞–ª–∏—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏
[1m[94m92 |[0m         assert normalized_df['bool_col'].iloc[0] == True
[1m[94m93 |[0m         assert normalized_df['bool_col'].iloc[1] == False
   [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m94 |[0m         assert normalized_df['bool_col'].iloc[3] == True
[1m[94m95 |[0m         assert normalized_df['bool_col'].iloc[4] == False
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not normalized_df['bool_col'].iloc[1]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `normalized_df['bool_col'].iloc[3]:` for truth checks[0m
  [1m[94m-->[0m tests/test_data_normalization.py:94:16
   [1m[94m|[0m
[1m[94m92 |[0m         assert normalized_df['bool_col'].iloc[0] == True
[1m[94m93 |[0m         assert normalized_df['bool_col'].iloc[1] == False
[1m[94m94 |[0m         assert normalized_df['bool_col'].iloc[3] == True
   [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m95 |[0m         assert normalized_df['bool_col'].iloc[4] == False
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `normalized_df['bool_col'].iloc[3]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not normalized_df['bool_col'].iloc[4]:` for false checks[0m
  [1m[94m-->[0m tests/test_data_normalization.py:95:16
   [1m[94m|[0m
[1m[94m93 |[0m         assert normalized_df['bool_col'].iloc[1] == False
[1m[94m94 |[0m         assert normalized_df['bool_col'].iloc[3] == True
[1m[94m95 |[0m         assert normalized_df['bool_col'].iloc[4] == False
   [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m96 |[0m
[1m[94m97 |[0m     def test_empty_dataframe_normalization(self):
   [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not normalized_df['bool_col'].iloc[4]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `normalized_df['bool_col'].iloc[0]:` for truth checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:135:16
    [1m[94m|[0m
[1m[94m134 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ–ª–æ–Ω–∫—É
[1m[94m135 |[0m         assert normalized_df['bool_col'].iloc[0] == True
    [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m136 |[0m         assert normalized_df['bool_col'].iloc[1] == False
[1m[94m137 |[0m         assert pd.isna(normalized_df['bool_col'].iloc[2])
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `normalized_df['bool_col'].iloc[0]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not normalized_df['bool_col'].iloc[1]:` for false checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:136:16
    [1m[94m|[0m
[1m[94m134 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–æ–ª–æ–Ω–∫—É
[1m[94m135 |[0m         assert normalized_df['bool_col'].iloc[0] == True
[1m[94m136 |[0m         assert normalized_df['bool_col'].iloc[1] == False
    [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m137 |[0m         assert pd.isna(normalized_df['bool_col'].iloc[2])
[1m[94m138 |[0m         assert normalized_df['bool_col'].iloc[3] == True
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not normalized_df['bool_col'].iloc[1]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `normalized_df['bool_col'].iloc[3]:` for truth checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:138:16
    [1m[94m|[0m
[1m[94m136 |[0m         assert normalized_df['bool_col'].iloc[1] == False
[1m[94m137 |[0m         assert pd.isna(normalized_df['bool_col'].iloc[2])
[1m[94m138 |[0m         assert normalized_df['bool_col'].iloc[3] == True
    [1m[94m|[0m                [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m139 |[0m         
[1m[94m140 |[0m         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ index –æ—Å—Ç–∞–ª—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `normalized_df['bool_col'].iloc[3]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `result_df['is_active'].iloc[0]:` for truth checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:191:20
    [1m[94m|[0m
[1m[94m190 |[0m             # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
[1m[94m191 |[0m             assert result_df['is_active'].iloc[0] == True
    [1m[94m|[0m                    [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m192 |[0m             assert result_df['is_active'].iloc[1] == False
[1m[94m193 |[0m             assert pd.isna(result_df['is_active'].iloc[2])  # NaN -> NA
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `result_df['is_active'].iloc[0]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `False`; use `not result_df['is_active'].iloc[1]:` for false checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:192:20
    [1m[94m|[0m
[1m[94m190 |[0m             # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
[1m[94m191 |[0m             assert result_df['is_active'].iloc[0] == True
[1m[94m192 |[0m             assert result_df['is_active'].iloc[1] == False
    [1m[94m|[0m                    [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m193 |[0m             assert pd.isna(result_df['is_active'].iloc[2])  # NaN -> NA
[1m[94m194 |[0m             assert result_df['is_active'].iloc[3] == True
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `not result_df['is_active'].iloc[1]`[0m

[1m[91mE712 [0m[1mAvoid equality comparisons to `True`; use `result_df['is_active'].iloc[3]:` for truth checks[0m
   [1m[94m-->[0m tests/test_data_normalization.py:194:20
    [1m[94m|[0m
[1m[94m192 |[0m             assert result_df['is_active'].iloc[1] == False
[1m[94m193 |[0m             assert pd.isna(result_df['is_active'].iloc[2])  # NaN -> NA
[1m[94m194 |[0m             assert result_df['is_active'].iloc[3] == True
    [1m[94m|[0m                    [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
[1m[94m195 |[0m             
[1m[94m196 |[0m         finally:
    [1m[94m|[0m
[1m[96mhelp[0m: [1mReplace with `result_df['is_active'].iloc[3]`[0m

[1m[91mE501 [0m[1mLine too long (103 > 100)[0m
  [1m[94m-->[0m tests/test_deterministic_output.py:35:101
   [1m[94m|[0m
[1m[94m33 |[0m             "activity_unit": ["nM", "nM"],
[1m[94m34 |[0m             "source": ["chembl", "chembl"],
[1m[94m35 |[0m             "retrieved_at": pd.to_datetime(["2024-01-02T00:00:00Z", "2024-01-01T00:00:00Z"], utc=True),
   [1m[94m|[0m                                                                                                     [1m[91m^^^[0m
[1m[94m36 |[0m             "smiles": ["CCO", "CCC"],
[1m[94m37 |[0m         }
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
  [1m[94m-->[0m tests/test_deterministic_output.py:49:101
   [1m[94m|[0m
[1m[94m47 |[0m         correlation_path=tmp_path / "corr.csv",
[1m[94m48 |[0m         format="csv",
[1m[94m49 |[0m         csv=CsvFormatSettings(encoding="utf-8", float_format="%.1f", date_format="%Y-%m-%dT%H:%M:%S%z"),
   [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m50 |[0m         parquet=ParquetFormatSettings(compression=None),
[1m[94m51 |[0m     )
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (102 > 100)[0m
   [1m[94m-->[0m tests/test_deterministic_output.py:117:101
    [1m[94m|[0m
[1m[94m115 |[0m     )
[1m[94m116 |[0m     determinism = DeterminismSettings(
[1m[94m117 |[0m         sort=SortSettings(by=["document_chembl_id", "doi_key", "pmid"], ascending=[True, True, True]),
    [1m[94m|[0m                                                                                                     [1m[91m^^[0m
[1m[94m118 |[0m         column_order=[
[1m[94m119 |[0m             "document_chembl_id",
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (104 > 100)[0m
   [1m[94m-->[0m tests/test_doi_normalization.py:267:101
    [1m[94m|[0m
[1m[94m265 |[0m         test_data = {
[1m[94m266 |[0m             'index': [0, 1, 2, 3, 4],
[1m[94m267 |[0m             'doi': ["10.1000/test1", "10.1000/test2", "10.1000/test3", "10.1000/test4", "10.1000/test5"]
    [1m[94m|[0m                                                                                                     [1m[91m^^^^[0m
[1m[94m268 |[0m         }
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (133 > 100)[0m
   [1m[94m-->[0m tests/test_doi_normalization.py:276:101
    [1m[94m|[0m
[1m[94m274 |[0m         assert normalized_df['index'].tolist() == [0, 1, 2, 3, 4]
[1m[94m275 |[0m         # DOI-—Å—Ç–æ–ª–±—Ü—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã
[1m[94m276 |[0m         assert normalized_df['doi'].tolist() == ["10.1000/test1", "10.1000/test2", "10.1000/test3", "10.1000/test4", "10.1000/test5"]
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
  [1m[94m-->[0m tests/test_enhanced_correlation.py:81:101
   [1m[94m|[0m
[1m[94m79 |[0m         df = pd.DataFrame({
[1m[94m80 |[0m             'numeric': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] * 10,
[1m[94m81 |[0m             'category': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'] * 10,  # –ö–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å numeric
   [1m[94m|[0m                                                                                                     [1m[91m^^^^^[0m
[1m[94m82 |[0m             'binary': [True, True, False, False, True, False, True, False, True, False] * 10,
[1m[94m83 |[0m             'independent': ['X', 'Y', 'Z'] * 33 + ['X'],  # –ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è
   [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (105 > 100)[0m
   [1m[94m-->[0m tests/test_enhanced_qc.py:101:101
    [1m[94m|[0m
[1m[94m 99 |[0m [1m[94m‚Ä¶[0m     assert numbers_analysis['numeric_mean'] == 5.5
[1m[94m100 |[0m [1m[94m‚Ä¶[0m     
[1m[94m101 |[0m [1m[94m‚Ä¶[0m     # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–º–µ—à–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–º–æ–∂–µ—Ç –Ω–µ –∏–º–µ—Ç—å numeric_cov –µ—Å–ª–∏ pandas –Ω–µ —Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É —á–∏—Å–ª–æ–≤–æ–π)
    [1m[94m|[0m                                                                                                   [1m[91m^^^^^[0m
[1m[94m102 |[0m [1m[94m‚Ä¶[0m     mixed_analysis = report['column_analysis']['mixed']
[1m[94m103 |[0m [1m[94m‚Ä¶[0m     # –î–ª—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö numeric_cov –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
    [1m[94m|[0m

[1m[91mE501 [0m[1mLine too long (111 > 100)[0m
   [1m[94m-->[0m tests/test_enhanced_qc.py:135:101
    [1m[94m|[0m
[1m[94m133 |[0m             'category': ['X', 'Y', 'X', 'Z', 'Y'],  # categorical
[1m[94m134 |[0m             'text': ['hello world', 'test data', 'sample text', 'example', 'demo'],  # text
[1m[94m135 |[0m             'date': [datetime(2023, 1, 1), datetime(2023, 2, 1), None, datetime(2023, 3, 1), None],  # datetime
    [1m[94m|[0m                                                                                                     [1m[91m^^^^^^^^^^^[0m
[1m[94m136 |[0m         })
    [1m[94m|[0m

Found 202 errors.
No fixes available (16 hidden fixes can be enabled with the `--unsafe-fixes` option).
