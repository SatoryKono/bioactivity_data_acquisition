"""
–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ö–µ–º—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ –≤–Ω–µ—Å–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. DocumentETLWriter —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç column_order –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
2. DocumentNormalizedSchema —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
3. –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –ø–∞–π–ø–ª–∞–π–Ω
"""

import pandas as pd
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
from src.library.common.writer_base import DocumentETLWriter
from src.library.schemas.document_schema import DocumentNormalizedSchema
from src.library.documents.normalize import DocumentNormalizer
from src.library.config import Config

def test_document_etl_writer():
    """–¢–µ—Å—Ç DocumentETLWriter - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç column_order –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞."""
    print("=" * 80)
    print("–¢–ï–°–¢ 1: DocumentETLWriter –∏—Å–ø–æ–ª—å–∑—É–µ—Ç column_order –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–∫ –∫–æ–Ω—Ñ–∏–≥ —Å column_order
    class MockConfig:
        def __init__(self):
            self.determinism = MockDeterminism()
    
    class MockDeterminism:
        def __init__(self):
            self.column_order = [
                "document_chembl_id", "doi", "title", "abstract", "journal", "year"
            ]
    
    config = MockConfig()
    writer = DocumentETLWriter(config, "documents")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ get_column_order –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç column_order –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    column_order = writer.get_column_order()
    
    if column_order is not None:
        print("‚úÖ DocumentETLWriter.get_column_order() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç column_order –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞")
        print(f"   –ü–æ–ª—É—á–µ–Ω –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫: {column_order[:5]}... (–ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 5)")
    else:
        print("‚ùå DocumentETLWriter.get_column_order() –≤—Å–µ –µ—â–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None")
    
    return column_order is not None

def test_document_normalized_schema():
    """–¢–µ—Å—Ç DocumentNormalizedSchema - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç."""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢ 2: DocumentNormalizedSchema —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è")
    print("=" * 80)
    
    schema = DocumentNormalizedSchema.get_schema()
    schema_columns = set(schema.columns.keys())
    
    # –û–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–ª—è –∏–∑ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–≤–æ–¥–∞
    expected_columns = {
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
        "document_chembl_id", "document_pubmed_id", "document_classification",
        "referenses_on_previous_experiments", "original_experimental_document",
        
        # –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è
        "doi", "title", "abstract", "journal", "year", "volume", "issue",
        "first_page", "last_page", "citation", "month",
        
        # ChEMBL –ø–æ–ª—è
        "chembl_pmid", "chembl_title", "chembl_abstract", "chembl_authors",
        "chembl_doi", "chembl_doc_type", "chembl_issn", "chembl_journal",
        "chembl_year", "chembl_volume", "chembl_issue", "chembl_first_page",
        "chembl_last_page", "chembl_error",
        
        # Crossref –ø–æ–ª—è
        "crossref_pmid", "crossref_title", "crossref_abstract", "crossref_authors",
        "crossref_doi", "crossref_doc_type", "crossref_issn", "crossref_journal",
        "crossref_year", "crossref_volume", "crossref_issue", "crossref_first_page",
        "crossref_last_page", "crossref_subject", "crossref_error",
        
        # OpenAlex –ø–æ–ª—è
        "openalex_pmid", "openalex_title", "openalex_abstract", "openalex_authors",
        "openalex_doi", "openalex_doc_type", "openalex_crossref_doc_type",
        "openalex_issn", "openalex_journal", "openalex_year", "openalex_volume",
        "openalex_issue", "openalex_first_page", "openalex_last_page",
        "openalex_concepts", "openalex_type", "openalex_error",
        
        # PubMed –ø–æ–ª—è
        "pubmed_pmid", "pubmed_article_title", "pubmed_abstract", "pubmed_authors",
        "pubmed_doi", "pubmed_doc_type", "pubmed_issn", "pubmed_journal",
        "pubmed_year", "pubmed_volume", "pubmed_issue", "pubmed_first_page",
        "pubmed_last_page", "pubmed_mesh_descriptors", "pubmed_mesh_qualifiers",
        "pubmed_chemical_list", "pubmed_year_completed", "pubmed_month_completed",
        "pubmed_day_completed", "pubmed_year_revised", "pubmed_month_revised",
        "pubmed_day_revised", "pubmed_pages", "pubmed_pmcid", "pubmed_title",
        "pubmed_day", "pubmed_month", "pubmed_error",
        
        # Semantic Scholar –ø–æ–ª—è
        "semantic_scholar_pmid", "semantic_scholar_title", "semantic_scholar_authors",
        "semantic_scholar_doi", "semantic_scholar_doc_type", "semantic_scholar_issn",
        "semantic_scholar_journal", "semantic_scholar_abstract", "semantic_scholar_citation_count",
        "semantic_scholar_venue", "semantic_scholar_year", "semantic_scholar_error",
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è
        "index", "pipeline_version", "source_system", "chembl_release", "extracted_at",
        "hash_row", "hash_business_key", "extraction_errors", "validation_errors",
        "extraction_status", "retrieved_at",
        
        # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è
        "valid_doi", "valid_journal", "valid_year", "valid_volume", "valid_issue",
        "invalid_doi", "invalid_journal", "invalid_year", "invalid_volume", "invalid_issue",
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        "document_citation", "publication_date", "document_sortorder"
    }
    
    missing_columns = expected_columns - schema_columns
    extra_columns = schema_columns - expected_columns
    
    print(f"–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ö–µ–º–µ: {len(schema_columns)}")
    print(f"–û–∂–∏–¥–∞–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(expected_columns)}")
    
    if missing_columns:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ ({len(missing_columns)}):")
        for col in sorted(missing_columns):
            print(f"   - {col}")
    else:
        print("‚úÖ –í—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Å—Ö–µ–º–µ")
    
    if extra_columns:
        print(f"‚ö†Ô∏è  –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ö–µ–º–µ ({len(extra_columns)}):")
        for col in sorted(extra_columns):
            print(f"   - {col}")
    
    return len(missing_columns) == 0

def test_system_metadata():
    """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢ 3: –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –ø–∞–π–ø–ª–∞–π–Ω")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π DataFrame
    test_df = pd.DataFrame({
        'document_chembl_id': ['CHEMBL123', 'CHEMBL456'],
        'doi': ['10.1234/test1', '10.1234/test2'],
        'title': ['Test Title 1', 'Test Title 2']
    })
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä
    config = {
        'pipeline': {'version': '2.0.0'}
    }
    normalizer = DocumentNormalizer(config)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
    try:
        normalized_df = normalizer._add_system_metadata(test_df)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø–æ–ª–µ–π
        system_fields = [
            'index', 'pipeline_version', 'source_system', 'chembl_release',
            'extracted_at', 'hash_row', 'hash_business_key'
        ]
        
        missing_fields = []
        for field in system_fields:
            if field not in normalized_df.columns:
                missing_fields.append(field)
        
        if missing_fields:
            print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è: {missing_fields}")
            return False
        else:
            print("‚úÖ –í—Å–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è –¥–æ–±–∞–≤–ª–µ–Ω—ã:")
            for field in system_fields:
                print(f"   - {field}: {normalized_df[field].iloc[0] if len(normalized_df) > 0 else 'N/A'}")
            return True
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        return False

def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤."""
    print("–§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò –°–•–ï–ú–´ –î–û–ö–£–ú–ï–ù–¢–û–í")
    print("=" * 80)
    
    results = []
    
    # –¢–µ—Å—Ç 1: DocumentETLWriter
    results.append(test_document_etl_writer())
    
    # –¢–µ—Å—Ç 2: DocumentNormalizedSchema
    results.append(test_document_normalized_schema())
    
    # –¢–µ—Å—Ç 3: –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    results.append(test_system_metadata())
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\n" + "=" * 80)
    print("–ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢")
    print("=" * 80)
    
    passed = sum(results)
    total = len(results)
    
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å—Ö–µ–º—ã –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
    else:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞.")
    
    return passed == total

if __name__ == "__main__":
    main()
